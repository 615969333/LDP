<sect1 id="Web-Serving">
	
<title>Web-Serving</title>

<para>
The World Wide Web provides a simple method of publishing and linking
information across the Internet, and is responsible for popularising
the Internet to its current level. In the simplest case, a Web client
(or browser), such as Netscape or Internet Explorer, connects with a
Web server using a simple request/response protocol called HTTP
(Hypertext Transfer Protocol), and requests HTML (Hypertext Markup
Language) pages, images, Flash and other objects.

In mode modern situations, the Web server can also geneate pages
dynamically based on information returned from the user. Either way
setting up your own Web server is extremely simple. There are many
choices for Web serving under Linux. Some servers are very mature,
such as Apache, and are perfect for small and large sites alike.
Other servers programmed to be light and fast, and to have only a
limited feature set to reduce complexity. A search on freshmeat.net
will reveal a multitude of servers.

Most Linux distributions include Apache <http://www.apache.org>.
Apache is the number one server on the internet according to
http://www.netcraft.co.uk/survey/ . More than a half of all internet
sites are running Apache or one of it derivatives. Apache's advantages
include its modular design, stability and speed. Given the appropriate
hardware and configuration it can support the highest loads: Yahoo,
Altavista, GeoCities, and Hotmail are based on customized versions of
this server.

Optional support for SSL (which enables secure transactions) is also
available at:

 ·  http://www.apache-ssl.org/
 ·  http://raven.covalent.net/
 ·  http://www.c2.net/

  Related HOWTOs:

 ·  http://metalab.unc.edu/mdw/HOWTO/WWW-HOWTO.html
 ·  http://metalab.unc.edu/mdw/HOWTO/Virtual-Services-HOWTO.html
 ·  http://metalab.unc.edu/mdw/HOWTO/Intranet-Server-HOWTO.html
 ·  Web servers for Linux
    <http://www.linuxlinks.com/Software/Internet/WebServers/>

Dynamic Web content generation

Web scripting languages are even more common on Linux than databases
- basically, every language is available. This includes CGI, 
PHP 3 and 4, Perl, JSP, ASP (via closed source applications from
Chill!soft and Halycon Software) and ColdFusion.

PHP is an open source scripting language designed to churn out
dynamically produced Web content ranging from databases to browsers.
This inludes not only HTML, but also graphics, Macromedia Flash and
XML-based information. The latest versions of PHP provide impressive
speed improvements, install easily from packages and can be set up
quickly. PHP is the most popular Apache module and is used by over
two million sites, including Amazon.com, US telco giant Sprint,
Xoom Networks and Lycos. And unlike most other server side scripting
languages, developers (or those that employ them) can add their own
functions into the source to improve it. Supported databases include
those in the Database serving section and most ODBC compliant
databases. The language itself borrows its structure from Perl and C.

A number of web browsers exist for the Linux platform. Netscape
Navigator has been one of the choices from the very beginning and the
upcoming Mozilla (http://www.mozilla.org) will have a Linux version.
Another popular text based web browser is lynx. It is fast and handy
when no graphical environment is available.

 ·  Browser software for Linux
     <http://www.linuxlinks.com/Software/Internet/WebBrowsers/>
 ·  http://metalab.unc.edu/mdw/HOWTO/mini/Public-Web-Browser.html

Web browsers and servers speak an application protocol that runs on
top of TCP/IP, using it simply as a way to pass strings of bytes back
and forth. This protocol is called HTTP (Hyper-Text Transfer Protocol)
and we've already seen one command in it ?? the GET shown above.

When the GET command goes to www.tldp.org's webserver with service number 80,
it will be dispatched to a server daemon listening on port 80. Most Internet
services are implemented by server daemons that do nothing but wait on ports,
watching for and executing incoming commands.

If the design of the Internet has one overall rule, it's that all the parts
should be as simple and human-accessible as possible. HTTP, and its relatives
(like the Simple Mail Transfer Protocol, SMTP, that is used to move
electronic mail between hosts) tend to use simple printable-text commands
that end with a carriage-return/line feed.

This is marginally inefficient; in some circumstances you could get more
speed by using a tightly-coded binary protocol. But experience has shown that
the benefits of having commands be easy for human beings to describe and
understand outweigh any marginal gain in efficiency that you might get at the
cost of making things tricky and opaque.

Therefore, what the server daemon ships back to you via TCP/IP is also text.
The beginning of the response will look something like this (a few headers
have been suppressed):
HTTP/1.1 200 OK                                                              
Date: Sat, 10 Oct 1998 18:43:35 GMT                                          
Server: Apache/1.2.6 Red Hat                                                 
Last-Modified: Thu, 27 Aug 1998 17:55:15 GMT                                 
Content-Length: 2982                                                         
Content-Type: text/html                                                      

These headers will be followed by a blank line and the text of the web page
(after which the connection is dropped). Your browser just displays that
page. The headers tell it how (in particular, the Content-Type header tells
it the returned data is really HTML).     
</para>

  Linux WWW HOWTO
  by Wayne Leister, n3mtr@qis.net
  v0.82, 19 November 1997

  This document contains information about setting up WWW services under
  Linux (both server and client).  It tries not to be a in detail manual
  but an overview and a good pointer to further information.

  Archived Document Notice: This document has been archived by the LDP
  because it is severely out-of-date. If you are interested in
  maintaining this document, contact The Linux Documentation Project.
  ______________________________________________________________________

  1.  Introduction


  Many people are trying Linux because they are looking for a really
  good Internet capable operating system.  Also, there are institutes,
  universities, non-profits, and small businesses which want to set up
  Internet sites on a small budget. This is where the WWW-HOWTO comes
  in. This document explains how to set up clients and servers for the
  largest part of the Internet - The World Wide Web.

  All prices in this document are stated in US dollars.  This document
  assumes you are running Linux on an Intel platform.  Instructions and
  product availability my vary from platform to platform.  There are
  many links for downloading software in this document.  Whenever
  possible use a mirror site for faster downloading and to keep the load
  down on the main server.

  The US government forbids US companies from exporting encryption
  stronger than 40 bit in strength.  Therefore US companies will usually
  have two versions of software.  The import version will usually
  support 128 bit, and the export only 40 bit.  This applies to web
  browsers and servers supporting secure transactions.  Another name for
  secure transactions is Secure Sockets Layer (SSL).  We will refer to
  it as SSL for the rest of this document.


  1.1.  Copyright

  This document is Copyright (c) 1997 by Wayne Leister.  The original
  author of this document was Peter Dreuw.(All versions prior to 0.8)


       This HOWTO is free documentation; you can redistribute it
       and/or modify it under the terms of the GNU General Public
       License as published by the Free Software Foundation; either
       version 2 of the License, or (at your option) any later ver­
       sion.



       This document is distributed in the hope that it will be
       useful, but without any warranty; without even the implied
       warranty of merchantability or fitness for a particular pur­
       pose.  See the GNU General Public License for more details.



       You can obtain a copy of the GNU General Public License by
       writing to the Free Software Foundation, Inc., 675 Mass Ave,
       Cambridge, MA 02139, USA.


  Trademarks are owned by there respective owners.


  1.2.  Feedback

  Any feedback is welcome.  I do not claim to be an expert.  Some of
  this information was taken from badly written web sites; there are
  bound to be errors and omissions.  But make sure you have the latest
  version before you send corrections; It may be fixed in the next
  version (see the next section for where to get the latest version).
  Send feedback to n3mtr@qis.net.


  1.3.  New versions of this Document

  New versions of this document can be retrieved in text format from
  Sunsite at <http://sunsite.unc.edu/pub/Linux/docs/HOWTO/WWW-HOWTO> and
  almost any Linux mirror site.  You can view the latest HTML version on
  the web at <http://sunsite.unc.edu/LDP/HOWTO/WWW-HOWTO.html>.  There
  are also HTML versions available on Sunsite in a tar archive.


  2.  Setting up WWW client software

  The following chapter is dedicated to the setting up web browsers.
  Please feel free to contact me, if your favorite web browser is not
  mentioned here.   In this version of the document only a few of the
  browsers have there own section, but I tried to include all of them
  (all I could find) in the overview section.  In the future those
  browsers that deserve there own section will have it.

  The overview section is designed to help you decide which browser to
  use, and give you basic information on each browser.  The detail
  section is designed to help you install, configure, and maintain the
  browser.

  Personally, I prefer the Netscape; it is the only browser that keeps
  up with the latest things in HTML.  For example, Frames, Java,
  Javascript, style sheets, secure transactions, and layers.  Nothing is
  worse than trying to visit a web site and finding out that you can't
  view it because your browser doesn't support some new feature.

  However I use Lynx when I don't feel like firing up the X-
  windows/Netscape monster.


  2.1.  Overview


     ``Navigator/Communicator''
        Netscape Navigator is the only browser mentioned here, which is
        capable of advanced HTML features.  Some of these features are
        frames, Java, Javascript, automatic update, and layers.  It also
        has news and mail capability.  But it is a resource hog; it
        takes up lots of CPU time and memory.  It also sets up a
        separate cache for each user wasting disk space.  Netscape is a
        commercial product.  Companies have a 30 day trial period, but
        there is no limit for individuals.  I would encourage you to
        register anyway to support Netscape in there efforts against
        Microsoft (and what is a measly $40US).  My guess is if
        Microsoft wins, we will be forced to use MS Internet Explorer on
        a Windows platform :(


     ``Lynx''
        Lynx is the one of the smallest web browsers.  It is the king of
        text based browsers.  It's free and the source code is available
        under the GNU public license.  It's text based, but it has many
        special features.


     Kfm
        Kfm is part of the K Desktop Environment (KDE).  KDE is a system
        that runs on top of X-windows.  It gives you many features like
        drag an drop, sounds, a trashcan and a unified look and feel.
        Kfm is the K File Manager, but it is also a web browser.  Don't
        be fooled by the name, for a young product it is very usable as
        a web browser.  It already supports frames, tables, ftp
        downloads, looking into tar files, and more.  The current
        version of Kfm is 1.39, and it's free.  Kfm can be used without
        KDE, but you still need the librarys that come with KDE.  For
        more information about KDE and Kfm visit the KDE website at
        <http://www.kde.org>.


     ``Emacs''
        Emacs is the one program that does everything.  It is a word
        processor, news reader, mail reader, and web browser.  It has a
        steep learning curve at first, because you have to learn what
        all the keys do.  The X-windows version is easier to use,
        because most of the functions are on menus.  Another drawback is
        that it's mostly text based. (It can display graphics if you are
        running it under X-windows).  It is also free, and the source
        code is available under the GNU public license.


     NCSA Mosaic
        Mosaic is an X-windows browser developed by the National Center
        for Supercomputing Applications (NCSA) at the University of
        Illinois.  NCSA spent four years on the project and has now
        moved on to other things.  The latest version is 2.6 which was
        released on July 7, 1995.  Source code is available for non-
        commercial use.  Spyglass Inc. <http://www.spyglass.com> has the
        commercial rights to Mosaic.  Its a solid X-windows browser, but
        it lacks the new HTML features.  For more info visit the NCSA
        Mosaic home page at
        <http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/>.  The software
        can be downloaded from
        <ftp://ftp.ncsa.uiuc.edu/Mosaic/Unix/binaries/2.6/Mosaic-
        linux-2.6.Z>.


     Arena
        Arena was a X-windows concept browser for the W3C (World Wide
        Web Consortium) when they were testing HTML 3.0.  Hence it
        supports all the HTML 3.0 standards such as style sheets and
        tables.  Development was taken over by Yggdrasil Computing, with
        the idea to turn it into a full fledge free X-windows browser.
        However development has stopped in Feb 1997 with version 0.3.11.
        Only part of the HTML 3.2 standard has been implemented.  The
        source code is released under the GNU public licence.  For more
        information see the web site at
        <http://www.yggdrasil.com/Products/Arena/>.  It can be
        downloaded from <ftp://ftp.yggdrasil.com/pub/dist/web/arena/>.


     Amaya
        Amaya is the X-windows concept browser for the W3C for HTML 3.2.
        Therefore it supports all the HTML 3.2 standards.  It also
        supports some of the features of HTML 4.0.  It supports tables,
        forms, client side image maps, put publishing, gifs, jpegs, and
        png graphics.  It is both a browser and authoring tool.  The
        latest public release is 1.0 beta.  Version 1.1 beta is in
        internal testing and is due out soon.  For more information
        visit the Amaya web site at  <http://www.w3.org/Amaya/>.  It can
        be downloaded from <ftp://ftp.w3.org/pub/Amaya-LINUX-
        ELF-1.0b.tar.gz>.


     Red Baron
        Red Baron is an X-windows browser made by Red Hat Software.  It
        is bundled with The Official Red Hat Linux distribution.  I
        could not find much information on it, but I know it supports
        frames, forms and SSL.  If you use Red Baron, please help me
        fill in this section.  For more information visit the Red Hat
        website at <http://www.redhat.com>


     Chimera
        Chimera is a basic X-windows browser.  It supports some of the
        features of HTML 3.2.  The latest release is 2.0 alpha 6
        released August 27, 1997.  For more information visit the
        Chimera website at <http://www.unlv.edu/chimera/>.  Chimera can
        be downloaded from <ftp://ftp.cs.unlv.edu/pub/chimera-
        alpha/chimera-2.0a6.tar.gz>.


     Qweb
        Qweb is yet another basic X-windows browser.  It supports
        tables, forms, and server site image maps.  The latest version
        is 1.3.  For more information visit the Qweb website at
        <http://sunsite.auc.dk/qweb/> The source is available from
        <http://sunsite.auc.dk/qweb/qweb-1.3.tar.gz> The binaries are
        available in a Red Hat RPM from
        <http://sunsite.auc.dk/qweb/qweb-1.3-1.i386.rpm>


     Grail
        Grail is an X-windows browser developed by the Corporation for
        National Research Initiatives (CNRI).  Grail is written entirely
        in Python, a interpreted object-oriented language.  The latest
        version is 0.3 released on May 7, 1997.  It supports forms,
        bookmarks, history, frames, tables, and many HTML 3.2 things.


     Internet Explorer
        There are rumors, that Microsoft is going to port the Internet
        Explorer to various Unix platforms - maybe Linux.  If its true
        they are taking their time doing it.  If you know something more
        reliable, please drop me an e-mail.


  In my humble opinion most of the above software is unusable for
  serious web browsing.  I'm not trying to discredit the authors, I know
  they worked very hard on these projects.  Just think, if all of these
  people had worked together on one project, maybe we would have a free
  browser that would rival Netscape and Internet Explorer.

  In my opinion out of all of the broswers, Netscape and Lynx are the
  best.  The runners up would be Kfm, Emacs-W3 and Mosaic.



  3.  Lynx

  Lynx is one of the smaller (around 600 K executable) and faster web
  browsers available. It does not eat up much bandwidth nor system
  resources as it only deals with text displays.  It can display on any
  console, terminal or xterm. You will not need an  X Windows system or
  additional system memory to run this little browser.


  3.1.  Where to get

  Both the Red Hat and Slackware distributions have Lynx in them.
  Therefore I will not bore you with the details of compiling and
  installing Lynx.

  The latest version is 2.7.1 and can be retrieved from
  <http://www.slcc.edu/lynx/fote/> or from almost any friendly Linux FTP
  server like ftp://sunsite.unc.edu under /pub/Linux/apps/www/broswers/
  or mirror site.

  For more information on Lynx try these locations:

     Lynx Links
        <http://www.crl.com/~subir/lynx.html>

     Lynx Pages
        <http://lynx.browser.org>

     Lynx Help Pages
        <http://www.crl.com/~subir/lynx/lynx_help/lynx_help_main.html>
        (the same pages you get from lynx --help and typing ? in lynx)

  Note: The Lynx help pages have recently moved.  If you have an older
  version of Lynx, you will need to change your lynx.cfg (in /usr/lib)
  to point to the new address(above).

  I think the most special feature of Lynx against all other web
  browsers is the capability for batch mode retrieval. One can write a
  shell script which retrieves a document, file or anything like that
  via http, FTP, gopher, WAIS, NNTP or file:// - url's and save it to
  disk.  Furthermore, one can fill in data into HTML forms in batch mode
  by simply redirecting the standard input and using the -post_data
  option.

  For more special features of Lynx just look at the help files and the
  man pages.  If you use a special feature of Lynx that you would like
  to see added to this document, let me know.



  4.  Emacs-W3

  There are several different flavors of Emacs.  The two most popular
  are GNU Emacs and XEmacs.  GNU Emacs is put out by the Free Software
  Foundation, and is the original Emacs.  It is mainly geared toward
  text based terminals, but it does run in X-Windows.  XEmacs (formerly
  Lucid Emacs) is a version that only runs on X-Windows.  It has many
  special features that are X-Windows related (better menus etc).


  4.1.  Where to get


  Both the Red Hat and Slackware distributions include GNU Emacs.

  The most recent GNU emacs is 19.34.  It doesn't seem to have a web
  site.  The FTP site is at  <ftp://ftp.gnu.ai.mit.edu/pub/gnu/>.

  The latest version of XEmacs is 20.2.  The XEmacs FTP site is at
  <ftp://ftp.xemacs.org/pub/xemacs>.  For more information about XEmacs
  goto see its web page at <http://www.xemacs.org>.

  Both are available from the Linux archives at ftp://sunsite.unc.edu
  under /pub/Linux/apps/editors/emacs/


  If you got GNU Emacs or XEmacs installed, you probably got the W3
  browser running to.

  The Emacs W3 mode is a nearly fully featured web browser system
  written in the Emacs Lisp system. It mostly deals with text, but can
  display graphics, too - at least - if you run the emacs under the X
  Window system.

  To get XEmacs in to W3 mode, goto the apps menu and select browse the
  web.

  I don't use Emacs, so if someone will explain how to get it into the
  W3 mode I'll add it to this document.  Most of this information was
  from the original author.  If any information is incorrect, please let
  me know.  Also let me know if you think anything else should be added
  about Emacs.



  5.  Netscape Navigator/Communicator


  5.1.  Different versions and options.

  Netscape Navigator is the King of WWW browsers.  Netscape Navigator
  can do almost everything. But on the other hand, it is one of the most
  memory hungry and resource eating program I've ever seen.

  There are 3 different versions of the program:

  Netscape Navigator includes the web browser, netcaster (push client)
  and a basic mail program.

  Netscape Communicator includes the web browser, a web editor, an
  advanced mail program, a news reader, netcaster (push client), and a
  group conference utility.

  Netscape Communicator Pro includes everything Communicator has plus a
  group calendar, IBM terminal emulation, and remote administration
  features (administrators can update thousands of copies of Netscape
  from their desk).

  In addition to the three versions there are two other options you must
  pick.

  The first is full install or base install.  The full install includes
  everything.  The base install includes enough to get you started.  You
  can download the additional components as you need them (such as
  multimedia support and netcaster).  These components can be installed
  by the Netscape smart update utility (after installing goto
  help->software updates).  At this time the full install is not
  available for Linux.

  The second option is import or export.  If you are from the US are
  Canada you have the option of selecting the import version.  This
  gives you the stronger 128 bit encryption for secure transactions
  (SSL).  The export version only has 40 bit encryption, and is the only
  version allowed outside the US and Canada.

  The latest version of the Netscape Navigator/Communicator/Communicator
  Pro is 4.03.  There are two different versions for Linux.  One is for
  the old 1.2 series kernels and one for the new 2.0 kernels.  If you
  don't have a 2.0 kernel I suggest you upgrade; there are many
  improvements in the new kernel.

  Beta versions are also available.  If you try a beta version, they
  usually expire in a month or so!


  5.2.  Where to get


  The best way to get Netscape software is to go through their web site
  at <http://www.netscape.com/download/>.  They have menu's to guide you
  through the selection.  When it ask for the Linux version, it is
  referring to the kernel (most people should be using 2.0 by now).  If
  your not sure which version kernel you have run 'cat /proc/version'.
  Going through the web site is the only way to get the import versions.

  If you want an export version you can download them directly from the
  Netscape FTP servers.  The FTP servers are also more up to date. For
  example when I first wrote this the web interface did not have the
  non-beta 4.03 for Linux yet, but it was on the FTP site.  Here are the
  links to the export Linux 2.0 versions:

  Netscape Navigator 4.03 is at
  <ftp://ftp.netscape.com/pub/communicator/4.03/shipping/english/unix/linux20/navigator_standalone/navigator-
  v403-export.x86-unknown-linux2.0.tar.gz>

  Netscape Communicator 4.03 for Linux 2.0 (kernel) is at
  <ftp://ftp.netscape.com/pub/communicator/4.03/shipping/english/unix/linux20/base_install/communicator-
  v403-export.x86-unknown-linux2.0.tar.gz>

  Communicator Pro 4.03 for Linux was not available at the time I wrote
  this.

  These url's will change as new versions come out.  If these links
  break you can find them by fishing around at the FTP site
  <ftp://ftp.netscape.com/pub/communicator/>.

  These servers are heavily loaded at times.  Its best to wait for off
  peak hours or select a mirror site.  Be prepared to wait, these
  archives are large.  Navigator is almost 8megs, and Communicator base
  install is 10megs.


  5.3.  Installing

  This section explains how to install version 4 of Netscape Navigator,
  Communicator, and Communicator Pro.

  First unpack the archive to a temporary directory.  Then run the ns-
  install script (type ./ns-install).  Then make a symbolic link from
  the /usr/local/netscape/netscape binary to /usr/local/bin/netscape
  (type ln -s /usr/local/netscape/netscape /usr/local/bin/netscape).
  Finally set the system wide environment variable $MOZILLA_HOME to
  /usr/local/netscape so Netscape can find its files.  If you are using
  bash for your shell edit your /etc/profile and add the lines:



       MOZILLA_HOME="/usr/local/netscape"
       export MOZILLA_HOME



  After you have it installed the software can automatically update
  itself with smart update.  Just run Netscape as root and goto
  help->software updates.  If you only got the base install, you can
  also install the Netscape components from there.

  Note: This will not remove any old versions of Netscape, you must
  manually remove them by deleting the Netscape binary and Java class
  file (for version 3).



  6.  Setting up WWW server systems

  This section contains information on different http server software
  packages and additional server side tools like script languages for
  CGI programs etc.  There are several dozen web servers, I only covered
  those that are fully functional.  As some of these are commercial
  products, I have no way of trying them.  Most of the information in
  the overview section was pieced together from various web sites.  If
  there is any incorrect or missing information please let me know.

  For a technical description on the http mechanism, take a look at the
  RFC documents mentioned in the chapter "For further reading" of this
  HOWTO.

  I prefer to use the Apache server.  It has almost all the features you
  would ever need and its free!  I will admit that this section is
  heavily biased toward Apache.  I decided to concentrate my efforts on
  the Apache section rather than spread it out over all the web servers.
  I may cover other web servers in the future.



  6.1.  Overview


     Cern httpd
        This was the first web server.  It was developed by the European
        Laboratory for Particle Physics (CERN).  CERN httpd is no longer
        supported.  The CERN httpd server is reported to have some ugly
        bugs, to be quite slow and resource hungry.  The latest version
        is 3.0.  For more information visit the CERN httpd home page at
        <http://www.w3.org/Daemon/Status.html>.  It is available for
        download at
        <ftp://sunsite.unc.edu/pub/Linux/apps/www/servers/httpd-3.0.term.tpz>
        (no it is not a typo, the extension is actually .tpz on the
        site; probably should be .tgz)


     NCSA HTTPd
        The NCSA HTTPd server is the father to Apache (The development
        split into two different servers).   Therefore the setup files
        are very similar.  NCSA HTTPd is free and the source code is
        available.  This server not covered in this document, although
        reading the Apache section may give you some help.  The NCSA
        server was once popular, but most people are replacing it with
        Apache.  Apache is a drop in replacement for the NCSA
        server(same configuration files), and it fixes several
        shortcomings of the NCSA server.  NCSA HTTPd accounts for 4.9%
        (and falling) of all web servers. (source September 1997
        Netcraft survey <http://www.netcraft.com/survey/>).  The latest
        version is 1.5.2a.  For more information see the NCSA website at
        <http://hoohoo.ncsa.uiuc.edu>.


     ``Apache''
        Apache is the king of all web servers.  Apache and its source
        code is free.  Apache is modular, therefore it is easy to add
        features.  Apache is very flexible and has many, many features.
        Apache and its derivatives makes up 44% of all web domains (50%
        if you count all the derivatives).  There are over 695,000
        Apache servers in operation (source November 1997 Netcraft
        survey <http://www.netcraft.com/survey/>).

        The official Apache is missing SSL, but there are two
        derivatives that fill the gap.  Stronghold is a commercial
        product that is based on Apache.  It retails for $995; an
        economy version is available for $495 (based on an old version
        of Apache).  Stronghold is the number two secure server behind
        Netscape (source C2 net <http://www.c2.net/products/stronghold>
        and Netcraft survey <http://www.netcraft.com/survey/>).  For
        more information visit the Stronghold website at
        <http://www.c2.net/products/stronghold/>.  It was developed
        outside the US, so it is available with 128 bit SSL everywhere.

        Apache-SSL is a free implementation of SSL, but it is not for
        commercial use in the US (RSA has US patents on SSL technology).
        It can be used for non-commercial use in the US if you link with
        the free RSAREF library.  For more information see the website
        at <http://www.algroup.co.uk/Apache-SSL/>.


     Netscape Fast Track Server
        Fast Track was developed by Netscape, but the Linux version is
        put out by Caldera.  The Caldera site lists it as Fast Track for
        OpenLinux.  I'm not sure if it only runs on Caldera OpenLinux or
        if any Linux distribution will do (E-mail me if you have the
        answer).  Netscape servers account for 11.5% (and falling) of
        all web servers (source September 1997
        <http://www.netcraft.com/survey/>).  The server sells for $295.
        It is also included with the Caldera OpenLinux Standard
        distribution which sells for $399 ($199.50 educational).  The
        web pages tell of a nice administration interface and a quick 10
        minute setup.  The server has support for 40-bit SSL.  To get
        the full 128-bit SSL you need Netscape Enterprise Server.
        Unfortunately that is not available for Linux :( The latest
        version available for Linux is 2.0 (Version 3 is in beta, but
        its not available for Linux yet).  To buy a copy goto the
        Caldera web site at
        <http://www.caldera.com/products/netscape/netscape.html> For
        more information goto the Fast Track page at
        <http://www.netscape.com/comprod/server_central/product/fast_track/>



     WN WN has many features that make it attractive.  First it is
        smaller than the CERN, NCSA HTTPd, an Apache servers.  It also
        has many built-in features that would require CGI's.  For
        example site searches, enhanced server side includes.  It can
        also decompress/compress files on the fly with its filter
        feature.  It also has the ability to retrieve only part of a
        file with its ranges feature.  It is released under the GNU
        public license.  The current version is 1.18.3. For more
        information see the WN website at <http://hopf.math.nwu.edu/>.


     AOLserver
        AOLserver is made by America Online.  I'll admit that I was
        surprised by the features of a web server coming from AOL.  In
        addition to the standard features it supports database
        connectivity.  Pages can query a database by Structured Query
        Language (SQL) commands.  The database is access through Open
        Database Connectivity (ODBC).  It also has built-in search
        engine and TCL scripting.  If that is not enough you can add
        your own modules through the c Application Programming Interface
        (API).  I almost forgot to mention support for 40 bit SSL.  And
        you get all this for free!  For more information visit the
        AOLserver site at <http://www.aolserver.com/server/>


     Zeus Server
        Zeus Server was developed by Zeus Technology.  They claim that
        they are the fastest web server (using WebSpec96 benchmark).
        The server can be configured and controlled from a web browser!
        It can limit processor and memory resources for CGI's, and it
        executes them in a secure environment (whatever that means).  It
        also supports unlimited virtual servers.  It sells for $999 for
        the standard version.  If you want the secure server (SSL) the
        price jumps to $1699.  They are based outside the US so 128 bit
        SSL is available everywhere.  For more information visit the
        Zeus Technology website at <http://www.zeus.co.uk>.  The US
        website is at <http://www.zeus.com>.  I'll warn you they are
        cocky about the fastest web server thing.  But they don't even
        show up under top web servers in the Netcraft Surveys.


     CL-HTTP
        CL-HTTP stands for Common Lisp Hypermedia Server.  If you are a
        Lisp programmer this server is for you.  You can write your CGI
        scripts in Lisp.  It has a web based setup function.  It also
        supports all the standard server features.  CL-HTTP is free and
        the source code is available.  For more information visit the
        CL-HTTP website at <http://www.ai.mit.edu/projects/iiip/doc/cl-
        http/home-page.html> (could they make that url any longer?).

  If you have a commercial purpose (company web site, or ISP), I would
  strongly recommend that you use Apache.  If you are looking for easy
  setup at the expense of advanced features then the Zeus Server wins
  hands down.  I've also heard that the Netscape Server is easy to
  setup.  If you have an internal use you can be a bit more flexible.
  But unless one of them has a feature that you just have to use, I
  would still recommend using one of the three above.

  This is only a partial listing of all the servers available.  For a
  more complete list visit Netcraft at
  <http://www.netcraft.com/survey/servers.html> or Web Compare at
  <http://webcompare.internet.com>.



  7.  Apache

  The current version of Apache is 1.2.4.  Version 1.3 is in beta
  testing.  The main Apache site is at <http://www.apache.org/>.
  Another good source of information is Apacheweek at
  <http://www.apacheweek.com/>.  The Apache documentation is ok, so I'm
  not going to go into detail in setting up apache.  The documentation
  is on the website and is included with the source (in HTML format).
  There are also text files included with the source, but the HTML
  version is better.  The documentation should get a whole lot better
  once the Apache Documentation Project gets under way.  Right now most
  of the documents are written by the developers.  Not to discredit the
  developers, but they are a little hard to understand if you don't know
  the terminology.


  7.1.  Where to get

  Apache is included in the Red Hat, Slackware, and OpenLinux
  distributions.  Although they may not be the latest version, they are
  very reliable binaries.  The bad news is you will have to live with
  their directory choices (which are totally different from each other
  and the Apache defaults).

  The source is available from the Apache web site at
  <http://www.apache.org/dist/> Binaries are are also available at
  apache at the same place.  You can also get binaries from sunsite at
  <ftp://sunsite.unc.edu/pub/Linux/apps/www/servers/>.  And for those of
  us running Red Hat the latest binary RPM file can usually be found in
  the contrib directory at <ftp://ftp.redhat.com/pub/contrib/i386/>


  If your server is going to be used for commercial purposes, it is
  highly recommended that you get the source from the Apache website and
  compile it yourself.  The other option is to use a binary that comes
  with a major distribution.  For example Slackware, Red Hat, or
  OpenLinux distributions.  The main reason for this is security.  An
  unknown binary could have a back door for hackers, or an unstable
  patch that could crash your system. This also gives you more control
  over what modules are compiled in, and allows you to set the default
  directories.  It's not that difficult to compile Apache, and besides
  you not a real Linux user until you compile your own programs ;)



  7.2.  Compiling and Installing

  First untar the archive to a temporary directory.  Next change to the
  src directory.  Then edit the Configuration file if you want to
  include any special modules.  The most commonly used modules are
  already included.  There is no need to change the rules or makefile
  stuff for Linux.  Next run the Configure shell script (./Configure).
  Make sure it says Linux platform and gcc as the compiler.  Next you
  may want to edit the httpd.h file to change the default directories.
  The server home (where the config files are kept) default is
  /usr/local/etc/httpd/, but you may want to change it to just
  /etc/httpd/.  And the server root (where the HTML pages are served
  from) default is /usr/local/etc/httpd/htdocs/, but I like the
  directory /home/httpd/html (the Red Hat default for Apache).  If you
  are going to be using su-exec (see special features below) you may
  want to change that directory too.  The server root can also be
  changed from the config files too.  But it is also good to compile it
  in, just encase Apache can't find or read the config file.  Everything
  else should be changed from the config files.  Finally run make to
  compile Apache.

  If you run in to problems with include files missing, check the
  following things. Make sure you have the kernel headers (include
  files) installed for your kernel version. Also make sure you have
  these symbolic links in place:


       /usr/include/linux should be a link to /usr/src/linux/include/linux
       /usr/include/asm should be a link to /usr/src/linux/include/asm
       /usr/src/linux should be a link to the Linux source directory (ex.linux-2.0.30)



  Links can be made with ln -s, it works just like the cp command except
  it makes a link (ln -s source-dir destination-link)

  When make is finished there should be an executable named httpd in the
  directory.  This needs to be moved in to a bin directory.  /usr/sbin
  or /usr/local/sbin would be good choices.

  Copy the conf, logs, and icons sub-directories from the source to the
  server home directory.  Next rename 3 of the files files in the conf
  sub-directory to get rid of the -dist extension (ex. httpd.conf-dist
  becomes httpd.conf)

  There are also several support programs that are included with Apache.
  They are in the support directory and must be compiled and installed
  separately.  Most of them can be make by using the makefile in that
  directory (which is made when you run the main Configure script).  You
  don't need any of them to run Apache, but some of them make the
  administrators job easier.

  7.3.  Configuring

  Now you should have four files in your conf sub-directory (under your
  server home directory).  The httpd.conf sets up the server daemon
  (port number, user, etc).  The srm.conf sets the root document tree,
  special handlers, etc.  The access.conf sets the base case for access.
  Finally mime.types tells the server what mime type to send to the
  browser for each extension.

  The configuration files are pretty much self-documented (plenty of
  comments), as long as you understand the lingo.  You should read
  through them thoroughly before putting your server to work.  Each
  configuration item is covered in the Apache documentation.

  The mime.types file is not really a configuration file.  It is used by
  the server to translate file extensions into mime-types to send to the
  browser.  Most of the common mime-types are already in the file.  Most
  people should not need to edit this file.  As time goes on, more mime
  types will be added to support new programs.  The best thing to do is
  get a new mime-types file (and maybe a new version of the server) at
  that time.

  Always remember when you change the configuration files you need to
  restart Apache or send it the SIGHUP signal with kill for the changes
  to take effect.  Make sure you send the signal to the parent process
  and not any of the child processes.  The parent usually has the lowest
  process id number.  The process id of the parent is also in the
  httpd.pid file in the log directory.  If you accidently send it to one
  of the child processes the child will die and the parent will restart
  it.

  I will not be walking you through the steps of configuring Apache.
  Instead I will deal with specific issues, choices to be made, and
  special features.

  I highly recommend that all users read through the security tips in
  the Apache documentation.  It is also available from the Apache
  website at <http://www.apache.org/docs/mics/security_tips.html>.


  7.4.  Hosting virtual websites

  Virtual Hosting is when one computer has more than one domain name.
  The old way was to have each virtual host have its own IP address.
  The new way uses only one IP address, but it doesn't work correctly
  with browsers that don't support HTTP 1.1.

  My recommendation for businesses is to go with the IP based virtual
  hosting until most people have browsers that support HTTP 1.1 (give it
  a year or two).   This also gives you a more complete illusion of
  virtual hosting.  While both methods can give you virtual mail
  capabilities (can someone confirm this?), only IP based virtual
  hosting can also give you virtual FTP as well.

  If it is for a club or personal page, you may want to consider shared
  IP virtual hosting.  It should be cheaper than IP based hosting and
  you will be saving precious IP addresses.

  You can also mix and match IP and shared IP virtual hosts on the same
  server.  For more information on virtual hosting visit Apacheweek at
  <http://www.apacheweek.com/features/vhost>.



  7.4.1.  IP based virtual hosting

  In this method each virtual host has its own IP address.  By
  determining the IP address that the request was sent to, Apache and
  other programs can tell what domain to serve.  This is an incredible
  waste of IP space.  Take for example the servers where my virtual
  domain is kept.  They have over 35,000 virtual accounts, that means
  35,000 IP addresses.  Yet I believe at last count they had less than
  50 servers running.

  Setting this up is a two part process.  The first is getting Linux
  setup to accept more than one IP address.  The second is setting up
  apache to serve the virtual hosts.

  The first step in setting up Linux to accept multiple IP addresses is
  to make a new kernel.  This works best with a 2.0 series kernel (or
  higher).  You need to include IP networking and IP aliasing support.
  If you need help with compiling the kernel see the kernel howto
  <http://sunsite.unc.edu/LDP/HOWTO/Kernel-HOWTO.html>.

  Next you need to setup each interface at boot.  If you are using the
  Red Hat Distribution then this can be done from the control panel.
  Start X-windows as root, you should see a control panel.  Then double
  click on network configuration.  Next goto the interfaces panel and
  select your network card.  Then click alias at the bottom of the
  screen.  Fill in the information and click done.  This will need to be
  done for each virtual host/IP address.

  If you are using other distributions you may have to do it manually.
  You can just put the commands in the rc.local file in /etc/rc.d
  (really they should go in with the networking stuff).  You need to
  have a ifconfig and route command for each device.  The aliased
  addresses are given a sub device of the main one.  For example eth0
  would have aliases eth0:0, eth0:1, eth0:2, etc.  Here is an example of
  configuring a aliased device:


       ifconfig eth0:0 192.168.1.57
       route add -host 192.168.1.57 dev eth0:0



  You can also add a broadcast address and a netmask to the ifconfig
  command.  If you have alot of aliases you may want to make a for loop
  to make it easier.  For more information see the IP alias mini howto
  <http://sunsite.unc.edu/LDP/HOWTO/mini/IP-Alias.html>.

  Then you need to setup your domain name server (DNS) to serve these
  new domains.   And if you don't already own the domain names, you need
  to contact the Internic <http://www.internic.net> to register the
  domain names.  See the DNS-howto for information on setting up your
  DNS.

  Finally you need to setup Apache to server the virtual domain
  correctly.  This is in the httpd.conf configuration file near the end.
  They give you an example to go by.  All commands specific to that
  virtual host are put in between the virtualhost directive tags.  You
  can put almost any command in there.  Usually you set up a different
  document root, script directory, and log files. You can have almost
  unlimited number of virtual hosts by adding more virtualhost directive
  tags.

  In rare cases you may need to run separate servers if a directive is
  needed for a virtual host, but is not allowed in the virtual host
  tags.  This is done using the bindaddress directive.   Each server
  will have a different name and setup files.  Each server only responds
  to one IP address, specified by the bindaddress directive.  This is an
  incredible waste of system resources.


  7.4.2.  Shared IP virtual hosting

  This is a new way to do virtual hosting.  It uses a single IP address,
  thus conserving IP addresses for real machines (not virtual ones).  In
  the same example used above those 30,000 virtual hosts would only take
  50 IP addresses (one for each machine).  This is done by using the new
  HTTP 1.1 protocol.  The browser tells the server which site it wants
  when it sends the request.  The problem is browsers that don't support
  HTTP 1.1 will get the servers main page, which could be setup to
  provide a menu of virtual hosts available.  That ruins the whole
  illusion of virtual hosting.  The illusion that you have your own
  server.

  The setup is much simpler than the IP based virtual hosting.  You
  still need to get your domain from the Internic and setup your DNS.
  This time the DNS points to the same IP address as the original
  domain.  Then Apache is setup the same as before.  Since you are using
  the same IP address in the virtualhost tags, it knows you want Shared
  IP virtual hosting.

  There are several work arounds for older browsers.  I'll explain the
  best one.  First you need to make your main pages a virtual host
  (either IP based or shared IP).  This frees up the main page for a
  link list to all your virtual hosts.  Next you need to make a back
  door for the old browsers to get in.  This is done using the
  ServerPath directive for each virtual host inside the virtualhost
  directive.  For example by adding ServerPath /mysite/ to
  www.mysite.com old browsers would be able to access the site by
  www.mysite.com/mysite/.  Then you put the default page on the main
  server that politely tells them to get a new browser, and lists links
  to all the back doors of all the sites you host on that machine.  When
  an old browser accesses the site they will be sent to the main page,
  and get a link to the correct page.  New browsers will never see the
  main page and will go directly to the virtual hosts.  You must
  remember to keep all of your links relative within the web sites,
  because the pages will be accessed from two different URL's
  (www.mysite.com and www.mysite.com/mysite/).

  I hope I didn't lose you there, but its not an easy workaround.  Maybe
  you should consider IP based hosting after all.  A very similar
  workaround is also explained on the apache website at
  <http://www.apache.org/manual/host.html>.

  If anyone has a great resource for Shared IP hosting, I would like to
  know about it.  It would be nice to know what percent of browsers out
  there support HTTP 1.1, and to have a list of which browsers and
  versions support HTTP 1.1.


  7.5.  CGI scripts

  There are two different ways to give your users CGI script capability.
  The first is make everything ending in .cgi a CGI script.  The second
  is to make script directories (usually named cgi-bin).  You could also
  use both methods.  For either method to work the scripts must be world
  executable (chmod 711).  By giving your users script access you are
  creating a big security risk.  Be sure to do your homework to minimize
  the security risk.

  I prefer the first method, especially for complex scripting.  It
  allows you to put scripts in any directory.  I like to put my scripts
  with the web pages they work with.  For sites with allot of scripts it
  looks much better than having a directory full of scripts.  This is
  simple to setup.  First uncomment the .cgi handler at the end of the
  srm.conf file.  Then make sure all your directories have the option
  ExecCGI or All in the access.conf file.

  Making script directories is considered more secure.  To make a script
  directory you use the ScriptAlias directive in the srm.conf file.  The
  first argument is the Alias the second is the actual directory.  For
  example ScriptAlias /cgi-bin/ /usr/httpd/cgi-bin/ would make
  /usr/httpd/cgi-bin able to execute scripts.  That directory would be
  used whenever someone asked for the directory /cgi-bin/.  For security
  reasons you should also change the properties of the directory to
  Options none, AllowOveride none in the access.conf (just uncomment the
  example that is there).  Also do not make your script directories
  subdirectories of your web page directories.  For example if you are
  serving pages from /home/httpd/html/, don't make the script directory
  /home/httpd/html/cgi-bin; Instead make it /home/httpd/cgi-bin.

  If you want your users to have there own script directories you can
  use multiple ScriptAlias commands.  Virtual hosts should have there
  ScriptAlias command inside the virtualhost directive tags.  Does
  anyone know a simple way to allow all users to have a cgi-bin
  directory without individual ScriptAlias commands?



  7.6.  Users Web Directories

  There are two different ways to handle user web directories.  The
  first is to have a subdirectory under the users home directory
  (usually public_html).  The second is to have an entirely different
  directory tree for web directories.  With both methods make sure set
  the access options for these directories in the access.conf file.

  The first method is already setup in apache by default.  Whenever a
  request for /~bob/ comes in it looks for the public_html directory in
  bob's home directory.  You can change the directory with the UserDir
  directive in the srm.conf file.  This directory must be world readable
  and executable.  This method creates a security risk because for
  Apache to access the directory the users home directory must be world
  executable.

  The second method is easy to setup.  You just need to change the
  UserDir directive in the srm.conf file.  It has many different
  formats; you may want to consult the Apache documentation for
  clarification.  If you want each user to have their own directory
  under /home/httpd/, you would use UserDir /home/httpd.  Then when the
  request /~bob/ comes in it would translate to /home/httpd/bob/.  Or if
  you want to have a subdirectory under bob's directory you would use
  UserDir /home/httpd/*/html.  This would translate to
  /home/httpd/bob/html/ and would allow you to have a script directory
  too (for example /home/httpd/bob/cgi-bin/).


  7.7.  Daemon mode vs. Inetd mode

  There are two ways that apache can be run.  One is as a daemon that is
  always running (Apache calls this standalone).  The second is from the
  inetd super-server.

  Daemon mode is far superior to inetd mode.  Apache is setup for daemon
  mode by default.  The only reason to use the inetd mode is for very
  low use applications.  Such as internal testing of scripts, small
  company Intranet, etc.  Inetd mode will save memory because apache
  will be loaded as needed.   Only the inetd daemon will remain in
  memory.

  If you don't use apache that often you may just want to keep it in
  daemon mode and just start it when you need it.  Then you can kill it
  when you are done (be sure to kill the parent and not one of the child
  processes).

  To setup inetd mode you need to edit a few files.  First in
  /etc/services see if http is already in there.  If its not then add
  it:


       http    80/tcp



  Right after 79 (finger) would be a good place.  Then you need to edit
  the /etc/inetd.conf file and add the line for Apache:


       http    stream  tcp     nowait  root    /usr/sbin/httpd httpd



  Be sure to change the path if you have Apache in a different location.
  And the second httpd is not a typo; the inet daemon requires that.  If
  you are not currently using the inet daemon, you may want to comment
  out the rest of the lines in the file so you don't activate other ser­
  vices as well (FTP, finger, telnet, and many other things are usually
  run from this daemon).

  If you are already running the inet deamon (inetd), then you only need
  to send it the SIGHUP signal (via kill; see kill's man page for more
  info) or reboot the computer for changes to take effect.  If you are
  not running inetd then you can start it manually.  You should also add
  it to your init files so it is loaded at boot (the rc.local file may
  be a good choice).


  7.8.  Allowing put and delete commands

  The newer web publishing tools support this new method of uploading
  web pages by http (instead of FTP).  Some of these products don't even
  support FTP anymore!  Apache does support this, but it is lacking a
  script to handle the requests.  This script could be a big security
  hole, be sure you know what you are doing before attempting to write
  or install one.

  If anyone knows of a script that works let me know and I'll include
  the address to it here.

  For more information goto Apacheweek's article at
  <http://www.apacheweek.com/features/put>.


  7.9.  User Authentication/Access Control


  This is one of my favorite features.  It allows you to password
  protect a directory or a file without using CGI scripts.  It also
  allows you to deny or grant access based on the IP address or domain
  name of the client.  That is a great feature for keeping jerks out of
  your message boards and guest books (you get the IP or domain name
  from the log files).
  To allow user authentication the directory must have AllowOverrides
  AuthConfig set in the access.conf file.  To allow access control (by
  domain or IP address) AllowOverrides Limit must be set for that
  directory.

  Setting up the directory involves putting an .htaccess file in the
  directory.  For user authentication it is usually used with an
  .htpasswd and optionally a .htgroup file.  Those files can be shared
  among multiple .htaccess files if you wish.

  For security reasons I recommend that everyone use these directives in
  there access.conf file:



       <files ~ "/\.ht">
       order deny,allow
       deny from all
       </files>



  If you are not the administrator of the system you can also put it in
  your .htaccess file if AllowOverride Limit is set for your directory.
  This directive will prevent people from looking into your access
  control files (.htaccess, .htpasswd, etc).

  There are many different options and file types that can be used with
  access control.  Therefore it is beyond the scope of this document to
  describe the files.  For information on how to setup User
  Authentication see the Apacheweek feature at
  <http://www.apacheweek.com/features/userauth> or the NCSA pages at
  <http://hoohoo.ncsa.uiuc.edu/docs-1.5/tutorials/user.html>.


  7.10.  su-exec

  The su-exec feature runs CGI scripts as the user of the owner.
  Normally it is run as the user of the web server (usually nobody).
  This allows users to access there own files in CGI scripts without
  making them world writable (a security hole).  But if you are not
  careful you can create a bigger security hole by using the su-exec
  code.  The su-exec code does security checks before executing the
  scripts, but if you set it up wrong you will have a security hole.

  The su-exec code is not for amateurs.  Don't use it if you don't know
  what you are doing.  You could end up with a gaping security hole
  where your users can gain root access to your system.  Do not modify
  the code for any reason.  Be sure to read all the documentation
  carefully.  The su-exec code is hard to setup on purpose, to keep the
  amateurs out (everything must be done manually, no make file no
  install scripts).

  The su-exec code resides in the support directory of the source.
  First you need to edit the suexec.h file for your system.  Then you
  need to compile the su-exec code with this command:


       gcc suexec.c -o suexec



  Then copy the suexec executable to the proper directory.  The Apache
  default is /usr/local/etc/httpd/sbin/.  This can be changed by editing
  httpd.h in the Apache source and recompiling Apache.  Apache will only
  look in this directory, it will not search the path.  Next the file
  needs to be changed to user root (chown root suexec) and the suid bit
  needs to be set (chmod 4711 suexec).  Finally restart Apache, it
  should display a message on the console that su-exec is being used.

  CGI scripts should be set world executable like normal.  They will
  automaticaly be run as the owner of the CGI script.  If you set the
  SUID (set user id) bit on the CGI scripts they will not run.  If the
  directory or file is world or group writable the script will not run.
  Scripts owned by system users will not be run (root, bin, etc.).  For
  other security conditions that must be met see the su-exec
  documentation.  If you are having problems see the su-exec log file
  named cgi.log.

  Su-exec does not work if you are running Apache from inetd, it only
  works in daemon mode.  It will be fixed in the next version because
  there will be no inetd mode.  If you like playing around in source
  code, you can edit the http_main.c.  You want to get rid of the line
  where Apache announces that it is using the su-exec wrapper (It
  wrongly prints this in front of the output of everything).

  Be sure and read the Apache documentation on su-exec.  It is included
  with the source and is available on the Apache web site at
  <http://www.apache.org/docs/suexec.html>


  7.11.  Imagemaps

  Apache has the ability to handle server side imagemaps.  Imagemaps are
  images on webpages that take users to different locations depending on
  where they click.  To enable imagemaps first make sure the imagemap
  module is installed (its one of the default modules).  Next you need
  to uncomment the .map handler at the end of the srm.conf file.  Now
  all files ending in .map will be imagemap files.  Imagemap files map
  different areas on the image to separate links.  Apache uses map files
  in the standard NCSA format.  Here is an example of using a map file
  in a web page:


       <a href="/map/mapfile.map">
       <img src="picture.gif" ISMAP>
       </a>



  In this example mapfile.map is the mapfile, and picture.gif is the
  image to click on.

  There are many programs that can generate NCSA compatible map files or
  you can create them yourself.  For a more detailed discussion of
  imagemaps and map files see the Apacheweek feature at
  <http://www.apacheweek.com/features/imagemaps>.


  7.12.  SSI/XSSI

  Server Side Includes (SSI) adds dynamic content to otherwise static
  web pages.  The includes are embedded in the web page as comments.
  The web server then parses these includes and passes the results to
  the web server.  SSI can add headers and footers to documents, add
  date the document was last updated, execute a system command or a CGI
  script.  With the new eXtended Server Side Includes (XSSI) you can do
  a whole lot more.  XSSI adds variables and flow control statements
  (if, else, etc).  Its almost like having an programming language to
  work with.

  Parsing all HTML files for SSI commands would waste allot of system
  resources.  Therefore you need to distinguish normal HTML files from
  those that contain SSI commands.  This is usually done by changing the
  extension of the SSI enhanced HTML files.  Usually the .shtml
  extension is used.

  To enable SSI/XSSI first make sure that the includes module is
  installed.  Then edit srm.conf and uncomment the AddType and
  AddHandler directives for .shtml files.   Finally you must set Options
  Includes for all directories where you want to run SSI/XSSI files.
  This is done in the access.conf file.  Now all files with the
  extension .shtml will be parsed for SSI/XSSI commands.

  Another way of enabling includes is to use the XBitHack directive.  If
  you turn this on it looks to see if the file is executable by user.
  If it is and Options Includes is on for that directory, then it is
  treated as an SSI file.  This only works for files with the mime type
  text/html (.html .htm files).  This is not the preferred method.

  There is a security risk in allowing SSI to execute system commands
  and CGI scripts.  Therefore it is possible to lock that feature out
  with the Option IncludesNOEXEC instead of Option Includes in the
  access.conf file.  All the other SSI commands will still work.

  For more information see the Apache mod_includes documentation that
  comes with the source.  It is also available on the website at
  <http://www.apache.org/docs/mod/mod_include.html>.

  For a more detailed discussion of SSI/XSSI implementation see the
  Apacheweek feature at  <http://www.apacheweek.com/features/ssi>.

  For more information on SSI commands see the NCSA documentation at
  <http://hoohoo.ncsa.uiuc.edu/docs/tutorials/includes.html>.

  For more information on XSSI commands goto
  <ftp://pageplus.com/pub/hsf/xssi/xssi-1.1.html>.


  7.13.  Module system

  Apache can be extended to support almost anything with modules.  There
  are allot of modules already in existence.  Only the general interest
  modules are included with Apache.   For links to existing modules goto
  the

  Apache Module Registry at <http://www.zyzzyva.com/module_registry/>.

  For module programming information goto
  <http://www.zyzzyva.com/module_registry/reference/>



  8.  Web Server Add-ons

  Sorry this section has not been written yet.

  Coming soon: mSQL, PHP/FI, cgiwrap, Fast-cgi, MS frontpage extentions,
  and more.



  9.  FAQ


  There aren't any frequent asked questions - yet...



  10.  For further reading



  10.1.  O'Reilly & Associates Books

  In my humble opinion O'Reilly & Associates make the best technical
  books on the planet.  They focus mainly on Internet, Unix and
  programming related topics. They start off slow with plenty of
  examples and when you finish the book your an expert.  I think you
  could get by if you only read half of the book.  They also add some
  humor to otherwise boring subjects.

  They have great books on HTML, PERL, CGI Programming, Java,
  JavaScript, C/C++, Sendmail, Linux and much much more.  And the fast
  moving topics (like HTML) are updated and revised about every 6 months
  or so.  So visit the O'Reilly & Associates <http://www.ora.com/> web
  site or stop by your local book store for more info.

  And remember if it doesn't say O'Reilly & Associates on the cover,
  someone else probably wrote it.


  10.2.  Internet Request For Comments (RFC)


  ·  RFC1866 written by T. Berners-Lee and D. Connolly, "Hypertext
     Markup Language - 2.0", 11/03/1995

  ·  RFC1867 writtenm by E. Nebel and L. Masinter, "Form-based File
     Upload in HTML", 11/07/1995

  ·  RFC1942 written by D. Raggett, "HTML Tables", 05/15/1996

  ·  RFC1945 by T. Berners-Lee, R. Fielding, H. Nielsen, "Hypertext
     Transfer Protocol -- HTTP/1.0", 05/17/1996.

  ·  RFC1630 by T. Berners-Lee, "Universal Resource Identifiers in WWW:
     A Unifying Syntax for the Expression of Names and Addresses of
     Objects on the Network as used in the World-Wide Web", 06/09/1994

  ·  RFC1959 by T. Howes, M. Smith, "An LDAP URL Format", 06/19/1996


  A mSQL and perl Web Server Mini HOWTO
  Oliver Corff, corff@zedat.fu-berlin.de
  v0.1, 17 September 1997

  This Mini HOWTO, highly inspired by Michael Schilli's article
  Gebunkert: Datenbankbedienung mit Perl und CGI, published in the ger-
  man computer magazine iX 8/1997, describes how to build a SQL
  client/server database using WWW and HTML for the user interface.

  1.  About this Document

  1.1.  Intended Audience

  Everybody who wants to install a web server database but does not know
  which software is necessary and how it is installed should benefit
  from reading this text. This text provides all information necessary
  to get a SQL database for a web server going; it does not go into any
  detail of CGI programming, nor does it explain the SQL database
  language. Excellent books are available on both topics, and it is the
  intention of this text to provide a working platform based on which a
  user can then study CGI programming and SQL.

  For getting a small scale SQL system running (not the notorious
  example of a major airline booking system, or space mission management
  database) it will be sufficient to have the software described in this
  text and the documentation accompanying it. The user manual of msql (a
  database introduced in this text) provides sufficient information on
  SQL for building your own database.

  The reader of this text should have a working knowledge of how to
  obtain files via ftp if he has no access to CD-ROMs, and a basic
  understanding of how to build binaries from sources. Anyway, all steps
  explained in this text were tested on a real life system and should
  also work on the reader's system.


  1.2.  Conventions used in this text

  A user command:

  # make install



  Screen output from a program:


       Program installed. Read README for details on how to start.



  Sample code of a file:

  ______________________________________________________________________
  # My comment
  char letter;
  ______________________________________________________________________



  2.  Introduction

  It can be safely assumed that databases with a high volume of data or
  a complicated relational setup (like, perhaps,  a lexical database for
  a living language) must be accessible to many users and operators at
  the same time. Ideally, it should be possible to use existing
  different hardware and software platforms that can be combined into
  the actual system. In order to reduce the implementation cost, only
  one system, the database server, needs to be powerful; the user
  stations typically just display data and accept user commands, but the
  processing is done on one machine only which led to the name client-
  server database.  In addition, the user interface should be easy to
  maintain and should require as little as possible on the client side.

  A system which meets these criteria can be built around the following
  items of protocols, concepts and software:

  3.  Installation Procedure

  3.1.  Hardware Requirements

  No general statement can be made about the hardware requirements of a
  database server. Too much depends on the expected number of users, the
  kind of application, the network load etc. In a small environment with
  only a few users and little network traffic a i486-equivalent machine
  with 16 MB of RAM can be completely sufficient. Linux, the operating
  system, is very efficient in terms of resources, and can supply enough
  horse-power for running a broad variety of applications at the same
  time. Of course, faster processors and more RAM mean more speed, but
  much more important than the processor is the amount of RAM. The more
  RAM the system has the less it is forced to swap memory intensive
  processes to disk in case a bottleneck occurs.

  Given anything like 32 MB RAM and a PCI bus, searches and sorting
  operations can be done without much resorting to swap files etc.,
  resulting in lightening fast speed.

  The model installation described in this article was made on a IBM 686
  (133Mhz) with 32 MB RAM and a 1.2 GB IDE hard disk.  Assuming that the
  installation process starts from scratch, here is a list of the
  necessary steps.


  3.2.  Software Requirements


  The software described in this article is available from the Internet
  or from CD-ROM. The following products were used:

  o  Red Hat Linux PowerTools: 6 CD's Complete Easy-to-Use Red Hat 4.2,
     Summer '97; alternatively from http://www.redhat.com;

  o  msql SQL database server: it is now available in two versions. The
     versions have differences in the number of transactions they can
     handle, the administration interface, etc. The elder version,
     1.0.16, is available from Sunsite mirrors. The ELF executable can
     be found at sunsite:apps/database/sql/msql-1.0.16 or on CD-ROM
     (here: disc 4 of InfoMagic Linux Developer's Resource, 6-CD set,
     December 1996) or alternatively from the following URL:
     http://www.infomagic.com.

     The newer version, 2.0.1, can be directly obtained from Hughes'
     homepage in Australia (http://www.hughes.com.au) or from numerous
     mirror sites around the world;

  o  perl from CPAN: The Comprehensive Perl Archive Network.  Walnut
     Creek CDROM, ISBN 1-57176-077-6, May 1997;

  o  Michael Schilli's CGI example program from computer journal iX
     8/1997, pages 150--152, available via ftp from ftp.uni-
     paderborn.de:/doc/magazin/iX;


  3.3.  Installing the Operating System

  Linux is installed in form of the Red Hat Linux Distribution 4.2. In
  order to install successfully, the machine must either have a DOS-
  accessible CD-ROM drive, a bootable CD-ROM drive, or else a boot disk
  must be made following the instructions on the Linux CD.

  During installation the user has the choice to select and configure
  numerous software packages. It is convenient to select the following
  items now:


  o  TCP/IP network support,

  o  the http server Apache, and

  o  the scripting language perl, and

  o  the X Window System, as well as

  o  the browsers Arena (graphical) and Lynx (text-based).

  All these packages are provided with the Linux distribution.  If you
  do not install these packages now you still have the chance to do this
  later with the assistance of glint, the graphical and intuitive
  software package installation manager. Be sure to be root when
  installing these packages.

  It is beyond the scope of this article to describe the network
  installation and initialization procedure. Please consult the online
  (manpages, HTML, texinfo) and printed (Linux Bible, etc. etc.)
  documentation.

  The installation procedure of Red Hat is very mature and requires only
  little user attention besides the usual choices (like providing host
  names, etc.). Once the installation ends successfully, the system is
  basically ready to go.

  Installing the X Window System is not mandatory for a pure server but
  it makes local access and testing much easier. The X installation
  procedure is done by any of several programs; XF86Setup offers the
  most extensive self-testing facilities and needs the least handling of
  hairy details (like video clock programming, etc.). The only
  requirement is that the software can detect the video adapter. A cheap
  accelerated graphics adapter (like Trio S64 based cards prior to
  S64UV+) usually works ``out of the box''.

  At this point we assume that our system is up and running and that
  Apache, Perl and the X Window System have been successfully installed.
  We further assume that all standard structures like the file and
  directory structure are kept as they are defined in the installation.
  Last but not least we leave the host name as it is, and do at this
  moment accept the name localhost. We'll use this name for testing the
  installation; once the whole system works the true name can be added.
  Please note that the network setup also requires editing the files
  /etc/hosts, among others. Ideally this should be done with the
  administration tools provided to user root.


  3.4.  The http Server


  The http server supplied with Linux is known as Apache to humans and
  as httpd to the system. The manpage (man httpd) explains how to
  install and start the http daemon (hence httpd) but, as mentioned, if
  the installation went without problems then the server should be
  running.  You can verify the directory tree: there must be a directory
  /home/httpd/ with three subdirectories: ../cgi-bin/, ../html/ and
  ../icons/. In ../html/ there must be a file index.html. Later we will
  manipulate or replace this file by our own index.html. All
  configuration information is stored in/etc/httpd/conf/. The system is
  well preconfigured and does not need further setup provided the
  installation went without error.


  3.5.  The Browsers


  There are essentially three types of browsers available for Linux:
  pure text-based systems like Lynx, experimental and simple ones like
  Arena (free!) and commercial ones like Netscape (shareware!) with Java
  support. While Lynx and Arena come with Linux, Netscape must be
  procured from other sources. Netscape is available as a precombiled
  binary for Linux on ix86 architectures and will run ``out of the box''
  as soon as the archive is unpacked.
  3.5.1.  Configuring Lynx


  Once Lynx is started it will look for a `default URL' which is usually
  not very meaningful if the system does not have permanent Internet
  access.  In order to change the default URL (and lots of other
  configuration details) the system administrator should edit
  /usr/lib/lynx.cfg. The file is big, around 57000 bytes and contains
  occasionally contradicting information. It states its own home as
  /usr/local/lib/. Not far from top is a line beginning with STARTFILE.
  We replace this line by the following entry:
  STARTFILE:http://localhost and make sure that no spacing etc. is
  inserted:

  ______________________________________________________________________
  # STARTFILE:http://www.nyu.edu/pages/wsn/subir/lynx.html
  STARTFILE:http://localhost
  ______________________________________________________________________


  After saving the file, Lynx should now reveal our index.html document
  if started without arguments.


  3.5.2.  Configuring Arena


  Arena first looks for its own default URL when started without
  arguments.  This URL is hard-wired into the executable but can be
  overrun by the environment variable WWW_HOME. The system administrator
  can place a line saying WWW_HOME="http://localhost" in /etc/profile.
  The variable must then be exported, either by a separate statement
  (export WWW_HOME) or by appending WWW_HOME to the existing export
  statement:

  ______________________________________________________________________
  WWW_HOME="http://localhost"
  export WWW_HOME
  ______________________________________________________________________


  After relaunching a login shell, the new default URL is now system-
  wide known to Arena.



  3.5.3.  Installing and Configuring Netscape


  Netscape is a commercial product and thus not included with the Linux
  distributions. It is either downloadable from the Internet or
  available from software collections on CDROM. Netscape comes in form
  of precompiled binaries for every important hardware platform. For
  installation purposes, it is useful to create a directory
  /usr/local/Netscape/ where the archive is unpacked. The files can be
  kept in place (except for the Java library: follow the instructions in
  the README file that comes with the Netscape binary), and it is
  sufficient to create a soft link in /usr/local/bin/ by issuing the
  command

  # ln -s /usr/local/Netscape/netscape .


  from within /usr/local/bin/.


  Netscape is now ready for use and can be configured via the
  ``Options'' menu. In ``General Preferences'' there is a card
  ``Appearance'' with the entry ``Home Page Location''. Enter
  http://localhost here and do not forget to save the options (via
  ``Options'' --- ``Save Options'') before exiting Netscape. At the next
  startup, Netscape will now show the Apache `homepage'.


  3.6.  Cooperation of Apache and Browsers


  You can now conduct the first real test of both the browser and the
  http server: simply start any of the available browsers and the
  Apache: Red Hat Linux Web Server page will pop up.  This page shows
  the file locations and other basics of http server installation. If
  this page is not displayed please check whether the files mentioned
  above are in place and whether the browser configuration is correct.
  Close edited configuration files before you start the browser again.
  If all files are in place and the browsers seem to be configured
  correctly then examine the network setup of your machine. Either the
  host name is different from what was entered in the configuration, or
  the network setup as such is not correct. It is utterly important that
  /etc/hosts contains at least a line like

  ______________________________________________________________________
  127.0.0.1               localhost localhost.localdomain
  ______________________________________________________________________


  which implies that you can connect locally to your machine. One can
  verify this by issuing any network-sensitive command requiring a host
  name as argument, like telnet localhost (provided telnet is
  installed). If that does not work then the network setup must be veri-
  fied before continuing with the main task.



  3.7.  The Database Engine and its Installation


  Installing the database requires only little more preparation than the
  previous installation steps. There are a few SQL database engines
  available with different runtime and administrative requirements, and
  possibly one of the most straightforward systems is msql, or ``Mini-
  SQL'' by David Hughes. msql is shareware. Depending on the version
  used, commercial sites are charged USD 250.00 and more, private users
  are charged USD 65.00 and more, and only educational institutions and
  registered non-profit organizations can use this software free of
  charge.  Please note that the exact figures are provided in the
  licence notes of the database documentation. The figures given here
  serve as a rough indicator only.

  A few words are in place here why the author chose msql. First of all,
  there is personal experience. While searching for a database engine
  the author found msql to be about the easiest to install and maintain,
  and it provides enough coverage of the SQL language to meet general
  needs. Only when writing these lines, the author discovered the
  following words of praise in  Alligator Descartes' DBI FAQ (perl
  database interface FAQ):


       From the current author's point of view, if the dataset is
       relatively small, being tables of less than 1 million rows,
       and less than 1000 tables in a given database, then mSQL is
       a perfectly acceptable solution to your problem.  This
       database is extremely cheap, is wonderfully robust and has
  excellent support. [...]


  Msql is available in two versions now, msql-1.0.16 and msql-2.0.1,
  which differ in performance (not noticeable in small scale projects)
  and accompanying software (the newer version comes with more tools,
  its own scripting language, etc.).  We will describe both versions of
  msql since their installion differs in a few points.


  3.7.1.  Installing msql-1.0.16


  msql is available as source and as compiled executable with ELF
  support.  Using the ELF binaries makes installation easy since the
  archive file msql-1.0.16.ELF.tgz contains a complete absolute
  directory tree so that all directories are generated properly when
  unpacked from /.

  If you decide to compile msql-1.0.16 yourself and are going to use the
  MsqlPerl package rather than the DBI interface (see a detailed
  discussion on the difference between these two further down) then be
  prepared that MsqlPerl might complain during the test suites that some
  instruction inside msql failed. In this case a patch may be necessary
  which is described in the MsqlPerl documentation (file
  patch.lost.tables). Notably, this demands including three lines in
  msqldb.c after line 1400 which says  entry->def = NULL;:

          *(entry->DB) = 0;
          *(entry->table) = 0;
          entry->age = 0;


  The code fragment should now look like

  ______________________________________________________________________
          freeTableDef(entry->def);
          safeFree(entry->rowBuf);
          safeFree(entry->keyBuf);
          entry->def = NULL;
          *(entry->DB) = 0;
          *(entry->table) = 0;
          entry->age = 0;
  ______________________________________________________________________



  Compiling msql involves several steps. After unpacking the source
  archive, it is necessary to build a target directory. This is done by
  saying

  # make target


  If successful, the system will then answer with


       Build of target directory for Linux-2.0.30-i486 complete



  You must now change into this newly created directory and run a

  # ./setup

  command first. The ./ sequence is necessary to make sure that really
  the command setup in this directory and not another command which hap-
  pens to have the same name is executed. You will then be asked ques-
  tions on the location of the source directory and whether a root
  installation is desired. These questions answered, the system should
  then run a number of tests checking for available software (compilers,
  utilities etc.) and finally say


       Ready to build mSQL.

       You may wish to check "common/site.h" although the defaults should be
       fine.  When you're ready, type  "make all" to build the software



  We say

  # make all


  If everything went as intended, we'll read:


       make[2]: Leaving directory `/usr/local/Minerva/src/msql'
       <-- [msql] done

       Make of mSQL complete.
       You should now mSQL using make install

       NOTE : mSQL cannot be used free of charge at commercial sites.
              Please read the doc/License file to see what you have to do.

       make[1]: Leaving directory `/usr/local/Minerva/src'



  All binaries must then be made visible to the search paths by creating
  soft links in /usr/local/bin/. Change to that directory and issue the
  command

  # ln -s /usr/local/Minerva/bin/* .


  after which the links will be properly set.


  3.7.2.  Testing msql-1


  After the installation it is now possible to test whether the database
  works. Before anything else is done, the server daemon must be
  started.  The system administrator holding root privileges issues the
  command

  # msqld &


  (do not forget to add the &, otherwise msql won't run in the back-
  ground.) after which the following screen message appears:



  mSQL Server 1.0.16 starting ...

  Warning : Couldn't open ACL file: No such file or directory
  Without an ACL file global access is Read/Write



  This message tells us that everything so far worked since we did not
  set up any access restrictions. For the moment it is sufficient to
  start the msql daemon from within a shell but later we may want to
  have the system startup automatically execute this command for us.
  The command must then be mentioned in a suitable rc.d script.  Only
  now the administrator can issue the first genuine database command:

  # msqladmin create inventur


  msql replies by saying Database "inventur" created.. As a further
  proof, we find that the directory /usr/local/Minerva/msqldb/ contains
  now the empty subdirectory ../inventur/. We could manipulate the newly
  created database with the administration tools; these procedures are
  all covered in detail in the msql documentation.


  3.7.3.  Installing msql-2.0.1


  There is now a newer, more powerful version of Hughes' mSQL server
  available the installation of which is different in a few points.
  Installing msql-2 from scratch involves the following steps. Copy the
  archive to your extraction point, e. g.  /usr/local/msql-2/, then
  untar the archive:

  # tar xfvz msql-2.0.1.tar.gz



  Change to the root direction of the install tree and issue a

  # make target



  Change to targets and look for your machine type. There should be a
  new subdirectory Linux-(your version)-(your cpu)/.  Change to that
  directory and start the setup facility located here:

  # ./setup



  There is also a file site.mm which can be edited. Maybe you have got
  used to the directory name /usr/local/Minerva/ and want to preserve
  it? In this case change the INST_DIR=...  line to your desired target
  directory. Otherwise, leave everything as it is.

  Now you can start building the database:

  # make
  # make install



  If everything went successfully, we'll see a message like:


       [...]

       Installation of mSQL-2 complete.

       *********
       **   This is the commercial, production release of mSQL-2.0
       **   Please see the README file in the top directory of the
       **   distribution for license information.
       *********



  After all is installed properly we have to take care of the
  administration details. Here, the real differences from msql-1 begin.
  First, a user msql is created which is responsible for database
  administration.


  # adduser msql



  Then we have to change all ownerships in the mSQL directory to msql by
  saying:

  # cd /usr/local/Minerva
  # chown -R msql:msql *



  Then we create soft links for all database binaries in /usr/local/bin/
  by saying:

  # ln -s /usr/local/Minerva/bin/* .



  3.7.4.  Testing msql-2

  We can now start the database server by issuing the command msql2d &
  and should get a response similar to this one:


       Mini SQL Version 2.0.1
       Copyright (c) 1993-4 David J. Hughes
       Copyright (c) 1995-7 Hughes Technologies Pty. Ltd.
       All rights reserved.

               Loading configuration from '/usr/local/Minerva/msql.conf'.
               Server process reconfigured to accept 214 connections.
               Server running as user 'msql'.
               Server mode is Read/Write.

       Warning : No ACL file.  Using global read/write access.



  That looks perfect. The database is compiled and in place, and we can
  now continue with the perl modules since these rely partially on the
  presence of a working database server for testing.

  Accidentally, this is also a good moment to print the complete manual
  that comes with msql-2.0.1:

  # gzip -d manual.ps.gz
  # lpr manual.ps



  We can proceed to building the interfaces now, but it is a good idea
  to keep the newly created SQL server up and running since that makes
  testing the interface libraries somewhat simpler.



  3.8.  Choice of Interfaces: DBI/mSQL, MsqlPerl, and Lite

  A frequently quoted saying in the Camel Book (the authorative perl
  documentation) states that there is more than one way to achieve a
  result when using perl. This, alas, holds true for our model
  application, too. Basically there are three ways to access an msql
  database via CGI. First of all the question is whether or not perl
  shall be used. If we use perl (on which this article focuses) then we
  still have the choice between two completely different interface
  models. Besides using perl, we can also employ msql's own scripting
  language, called Lite, which is reasonably simple and a close clone of
  C.


  3.8.1.  DBI and DBD-mSQL

  By the time of this writing, using perl's generic database interface
  called DBI is the method of choice. DBI has a few advantages: It
  provides unified access control to a number of commercial databases
  with a single command set. The actual database in use on a given
  system is then contacted through a driver which effectively hides the
  pecularities of that database from the programmer. Being such, using
  DBI provides for a smooth transition between different databases by
  different makers. In one single script it is even possible to contact
  several different databases. Please refer to the DBI-FAQ for details.
  There is, however, one drawback: The DBI interface is still under
  development and shows rapidly galloping version numbers (sometimes
  with updates taking place within less than a month). Similarly, the
  individual database drivers are also frequently updated and may rely
  on specific versions of the database interface. Users making first-
  time installations should stick to the version numbers given in this
  article since other versions may cause compilation and testing
  problems the trouble shooting of which is nothing for the faint-
  hearted.



  3.8.2.  MsqlPerl

  MsqlPerl is a library for directly accessing msql from perl scripts.
  It bypasses the DBI interface and is fairly compact. Though it works
  fine with both versions of msql, its usage is not promoted anymore in
  favour of the generalized DBI interface. Nonetheless, in a given
  installation it may prove to be the interface of choice since it is
  small and easy to install. Notably, it has less version dependencies
  than revealed by the interaction of DBI and particular database
  drivers.
  3.8.3.  msql's own scripting language: Lite

  Last but not least msql-2 comes with its own scripting language: Lite.
  The language is a close relative of C stripped of its oddities with
  additional shell-like features (in a way, something like a very
  specialized version of perl). Lite is a simple language and is well
  documented in the msql-2 manual. The msql-2 package also comes with a
  sample application sporting Lite.

  We will not describe Lite here because it is well documented but
  fairly specific to msql-2, and because it is assumed that the readers
  of this article have a basic interest in and a basic understanding of
  perl.  Nonetheless it is highly recommended to have a closer look at
  Lite: it may well be the case that Lite offers the solution of choice
  in an exclusive msql-2 environment (implying no other databases are
  involved) due to its simplicity and straightforward concept.



  3.9.  Going the generic way: DBI and DBD-msql

  We assume that perl was installed during the system setup or via the
  package manager mentioned above. No further details will be given
  here.  Nonetheless we first test whether our version of perl is up to
  date:


  # perl -v



  perl should respond with the following message:



       This is perl, version 5.003 with EMBED
               Locally applied patches:
                 SUIDBUF - Buffer overflow fixes for suidperl security

               built under linux at Apr 22 1997 10:04:46
               + two suidperl security patches

       Copyright 1987-1996, Larry Wall
       [...]



  So far, everything is fine. The next step includes installing the perl
  libraries for databases in general (DBI), the msql driver (DBD-mSQL)
  and CGI. The CGI driver is necessary in any case.  The following
  archives are necessary:

  1. DBI-0.81.tar.gz

  2. DBD-mSQL-0.65.tar.gz

  3. CGI.pm-2.31.tar.gz (or higher)

  A caveat is necessary here for beginners: the test installation
  described here works fine using software with exactly these version
  numbers, and combinations of other versions failed in one or the other
  way. Debugging flawed version combinations is nothing for those who
  are not very familiar with the intimate details of the calling
  conventions etc. of the interfaces. Sometimes only a method is renamed
  while performing the same task, but sometimes the internal structure
  changes significantly. So, again, stick with these version numbers if
  you want to be on the safe side even if you discover that version
  numbers have increased in the meantime. Frequent updates of these
  interfaces are the rule rather than the exception, so you should
  really anticipate problems when installing other versions than those
  indicated here.

  It is very important that the database driver for mSQL (DBD-mSQL) is
  installed after the generic interface DBI.

  We start by creating the directory /usr/local/PerlModules/ as it is
  very important to keep the original perl directory tree untouched.  We
  could also choose a different directory name since the name is
  completely uncritical, and unfortunately that is not really mentioned
  in the README files of the verious perl modules.  Having copied the
  above-mentioned archives to /usr/local/PerlModules/ we unpack them
  saying

  # tar xzvf [archive-file]



  for every single of the three archives. Do not forget to supply the
  real archive name to tar. The installation process for the three
  modules is essentially stardardized; only the screen messages showing
  important steps of individual packages are reproduced here.


  3.9.1.  Installing perl's Database Interface DBI


  The database interface must always be installed before installing the
  specific database driver.  Unpacking the DBI archive creates the
  directory /usr/local/PerlModules/DBI-0.81/. Change to that directory.
  There are a README file (you should read it) and a perl-specific
  makefile. Now issue the command

  # perl Makefile.PL



  The system should answer with a lengthy message of which the most
  important part is shown here::



       [...]
       MakeMaker (v5.34)
       Checking if your kit is complete...
       Looks good
               NAME => q[DBI]
               PREREQ_PM => {  }
               VERSION_FROM => q[DBI.pm]
               clean => { FILES=>q[$(DISTVNAME)/] }
               dist => { DIST_DEFAULT=>q[clean distcheck disttest [...]
       Using PERL=/usr/bin/perl

       WARNING! By default new modules are installed into your 'site_lib'
       directories. Since site_lib directories come after the normal library
       directories you MUST delete old DBI files and directories from your

       Writing Makefile for DBI



  This looks good, as the program says, and we can proceed with the next
  step:

  # make


  If no error message occurs (the detailed protocol dumped on screen is
  not an error message) we test the newly installed library with the
  command

  # make test


  Watch the output for the following lines (you can always scroll back
  with [Shift]-[PgUp]):


       [...]
       t/basics............ok
       t/dbidrv............ok
       t/examp.............ok
       All tests successful.
       [...]
       DBI test application $Revision$
       Switch: DBI-0.81 Switch by Tim Bunce, 0.81
       Available Drivers: ExampleP, NullP, Sponge
       ExampleP: testing 2 sets of 5 connections:
       Connecting... 1 2 3 4 5
       Disconnecting...
       Connecting... 1 2 3 4 5
       Disconnecting...
       Made 10 connections in  0 secs ( 0.00 usr  0.00 sys =  0.00 cpu)

       test.pl done



  The final step is to install all files in their proper directories.
  The following command will take care of it:

  # make install


  No more duties are left. If for some reason the installation failed
  and you want to redo it do not forget to issue

  # make realclean


  first. This will remove stale leftovers of the previous installation.
  You can also remove the files which were installed by copying the
  screen contents (shown abbreviated)


       Installing /usr/lib/perl5/site_perl/i386-linux/./auto/DBI/DBIXS.h
       Installing /usr/lib/perl5/site_perl/i386-linux/./auto/DBI/DBI.so
       Installing /usr/lib/perl5/site_perl/i386-linux/./auto/DBI/DBI.bs
       [...]
       Writing /usr/lib/perl5/site_perl/i386-linux/auto/DBI/.packlist
       Appending installation info to /usr/lib/perl5/i386-linux/5.003/perllocal.pod



  into a file, replacing every Installing with rm. Provided you named
  the file uninstall you can then say

  # . uninstall


  which will remove the recently installed files.


  3.9.2.  perl's msql Driver DBD-mSQL


  The msql driver can only be installed after a successful installation
  of perl's generic database interface.

  The basic steps are the same as above; so first go through

  # perl Makefile.PL



  Here, the system should answer with an urgent warning to read the
  accompanying documentation. It will then detect where msql resides,
  and asks which version you use:



       $MSQL_HOME not defined. Searching for mSQL...
       Using mSQL in /usr/local/Hughes

        -> Which version of mSQL are you using [1/2]?



  State your correct version number. Quite a few lines of text will fol-
  low. Watch for the following ones:


       Splendid! Your mSQL daemon is running. We can auto-detect your configuration!

       I've auto-detected your configuration to be running on port: 1114



  You can now test the driver by saying

  # make test


  Again, a lengthy output follows. If it ends with


       Testing: $cursor->func( '_ListSelectedFields' ). This will fail.
               ok: not a SELECT in msqlListSelectedFields!
       Re-testing: $dbh->do( 'DROP TABLE testaa' )
               ok
       *** Testing of DBD::mSQL complete! You appear to be normal! ***



  you are on the safe side of life and can install your driver by saying

  # make install

  You are now ready to go and can skip the next paragraph.



  3.10.  The MsqlPerl Interface

  If you decide to use the exclusive MsqlPerl interface then no generic
  database driver is needed, only MsqlPerl-1.15.tar.gz, since, as
  mentioned earlier, MsqlPerl provides a direct interface between perl
  and the database server without using the DBI interface.  Installing
  and testing is straightforward.

  After saying perl Makefile.PL the make utility can be started.  First
  you have to answer the question where mSQL resides. If it resides in
  /usr/local/Minerva/ the default answer can be confirmed.

  Then do a make test. Before doing so you must ensure that you have a
  database named test and that you have read and write permissions for
  it. This can be done by

  # msqladmin create test



  3.11.  perl's CGI library


  Installing perl's CGI part is the simpliest of the three steps.
  Execute the following commands in the given order and everything is
  done:


  # perl Makefile.PL
  # make
  # make install



  Unlike the previous drivers this interface does not have a test option
  (# make test) whereas the other modules should be tested in any case.

  A subdirectory with CGI example scripts is also created. You can copy
  the contents of this directory into /home/http/cgi-bin/ and use the
  browser to experiment with the scripts.



  3.12.  Installation Checklist

  We went through the following steps, in this order:

  1. Install Linux with networking support

  2. Install a http server, e. g. Apache

  3. Install a browser, e. g. Arena, lynx or Netscape

  4. Install an SQL server, e. g. msql

  5. Install a suitable perl SQL interface


  6. Install the CGI files

  Finally, you can do some clean-up. All source trees for msql and the
  perl modules can be safely deleted (however, you should not delete
  your archive files!) since the binaries and documentation are now
  based in different directories.


  4.  Running an Example Database


  After completing the system installation we can now finally run a
  model application. Depending on the version of msql installed and the
  perl database interface used, we have to modify the sample programs in
  a few points.

  First however, the file index.html residing in /home/httpd/html/ must
  be modified to allow calling a sample database application. We can
  place our database (which we call database.cgi or inventur.cgi here
  despite its archive name perl.lst.ck) in /home/httpd/html/test/.

  We add one line (of course, depending on your installation choices)
  similar to the following to index.html:

  ______________________________________________________________________
  <LI>Test the <A HREF="test/database.cgi">Database, DBI:DBD-mSQL style!</A>
  <LI>Test the <A HREF="test/inventur.cgi">Database, MsqlPerl style!</A>
  ______________________________________________________________________


  Usually you should only pick one of these two choices but if you have
  both types of database interface installed you can leave both lines
  here as they are. You can then compare performance, etc.


  4.1.  Adapting the sample script for MsqlPerl

  Our sample script has to be told to use the MsqlPerl interface. The
  modification takes place in several locations. First, near the
  beginning of the file, we change the use clause:

  ______________________________________________________________________
  #
  # use DBI;            # Generisches Datenbank-Interface
  use Msql;
  ______________________________________________________________________



  Then, near line 27, the MsqlPerl syntax does not require the
  mentioning of a specific driver:

  ______________________________________________________________________
  # $dbh = DBI->connect($host, $database, '', $driver) ||
  $dbh = Msql->connect($host, $database) ||
  ______________________________________________________________________



  Then, from line 33 onward throughout the whole script,  we have to
  change all instances of do against query:



  ______________________________________________________________________
  # $dbh->do("SELECT * FROM hw") || db_init($dbh);
  $dbh->query("SELECT * FROM hw") || db_init($dbh);
  ______________________________________________________________________



  Finally, in MsqlPerl speak, line 207 can be commented out:

  ______________________________________________________________________
  # $sth->execute || msg("SQL Error:", $sth->errstr);
  ______________________________________________________________________



  In addition, it may become necessary to swap all errstr calls like the
  one in the preceding code fragment against errmsg.  This is also
  version dependent.

  After these modifications, the script should run smoothly.


  4.2.  Adapting the sample script for msql-2

  The SQL syntax was redefined during the development of mslq-2. The
  original script will fail to execute the table initialization
  statements in lines 45 -- 58. The primary key modifier is no longer
  supported by msql-2, and should simply be skipped:

  ______________________________________________________________________
      $dbh->do(<<EOT) || die $dbh->errstr; # Neue Personen-Tabelle
          create table person (
  # We do not need the 'primary key' modifier anymore in msql-2!
  #           pn        int primary key,   # Personalnummer
              pn        int,               # Personalnummer
              name      char(80),          # Nachname, Vorname
              raum      int                # Raumnummer
          )
  EOT
      $dbh->do(<<EOT) || die $dbh->errstr; # Neue Hardware-Tabelle
          create table hw (
  # We do not need the 'primary key' modifier anymore in msql-2!
  #           asset int primary key,       # Inventurnummer
              asset int,                   # Inventurnummer
              name   char(80),             # Bezeichnung
              person int                   # Besitzer
          )
  EOT
  ______________________________________________________________________



  Unfortunately, this specific script will then accept new entries with
  identical personnel numbers; the msql-1 modifier primary key intends
  to prevent exactly this behaviour. The msql-2 documentation shows how
  to use the CREATE INDEX clause to create unique entries.


  5.  Conclusion and Outlook

  If you have installed msql-2 on your system then you can have a look
  at the sample programs written in Lite, msql-2's own scripting
  language.

  Either version of msql comes with a basic set of administration tools
  which allow the user to create and drop tables (msqladmin) and examine
  database structures (relshow).

  The second generation msql (i.e. msql-2) has a few more genuinely
  useful utilities: msqlimport and msqlexport. These allow the dumping
  of flat line data files into and out of the SQL database. They can be
  used for loading quantities of existing data d'un coup into existing
  tables, or extract flat data from tables, and the user does not have
  to deal with writing a single line of perl or SQL or whatever code for
  this task.

  If you want to write your own perl scripts dealing with databases
  you'll find sufficient support in the example files and the extensive
  on-line documentation that comes with the DBI module.

  Anyway, you are now ready to go and present your data to the users of
  your own network, or even the WWW.

</sect1>
