<CHAPTER ID="Distributions">
<TITLE>Distribution specific installations</TITLE>
<SECT1><TITLE>Installing Mosix</TITLE>

<PARA> This chapter deals with installing Mosix and openMosix on different
distributions.  It won't be an exhaustive list of all the possible
combinations.  However throughout the chapter you should find enough 
information on installing Mosix in your environment.
</PARA>

<PARA>Techniques for installing multiple machines with Mosix will be 
discussed in the next chapter.
</PARA>
</SECT1>
<SECT1><TITLE>Getting  openMosix</TITLE>
<PARA>
You can download the latest versions of openMosix from http://sourceforge.net/project/showfiles.php?group_id=46729
You can either choose the binary (even in rpm) compiled for UP or SMP or download the source code.
You will need both the kernel patch or binaries and the userland tools.


Alternatively you can use the CVS version 

<PROGRAMLISTING>

cvs -d:pserver:anonymous@cvs.openmosix.sourceforge.net:/cvsroot/openmosix login
cvs -z3 -d:pserver:anonymous@cvs.openmosix.sourceforge.net:/cvsroot/openmosix co linux-openmosix
cvs -z3 -d:pserver:anonymous@cvs.openmosix.sourceforge.net:/cvsroot/openmosix co userspace-tools

</PROGRAMLISTING>
please take care that CVS trees DO BREAK now and then and that it might not be the easiest way to install Mosix ;-)

</PARA>
</SECT1>

<SECT1><TITLE>Getting  Mosix (obsolete)</TITLE>
<PARA>

You can download Mosix from the www.mosix.org
<ulink url="http://www.mosix.org/txt_distribution.html"><citetitle>http://www.mosix.org/txt_distribution.html</citetitle></ulink>

 for the Kernel Patches,   and after you accepted the License agreement 
<ulink url="http://www.mosix.org/txt_download.html"><citetitle>http://www.mosix.org/txt_download.html</citetitle></ulink>

 for the UserLand tools.

</PARA>
</SECT1>


<SECT1><TITLE>openMosix General Instructions</TITLE>
<SECT2><TITLE>Kernel Compilation</TITLE>
<PARA>


Always use pure vanilla kernel-sources from e.g. www.kernel.org to compile 
an openMosix kernel!
Be sure to use the right openMosix version depending on the 
kernel-version. 
Do not use the kernel that comes with any Linux-distribution; it won't 
work.
</PARA><PARA>
Download the actual version of openMosix and untar it in your 
kernel-source directory 
(e.g. /usr/src/linux-2.4.16). If your kernel-source directory is other 
than 
"/usr/src/linux-[version_number]" at least the creation of a symbolic link 
to 
"/usr/src/linux-[version_number]" is required.
Now apply the patch using the patch utility:
<PROGRAMLISTING>
patch -Np1 < openMosix1.5.2moshe
</PROGRAMLISTING>

This command displays now a list of patched files from the kernel-sources.
Enable the openMosix-options in the kernel-configuration e.g.
<PROGRAMLISTING>
...
CONFIG_MOSIX=y
# CONFIG_MOSIX_TOPOLOGY is not set
CONFIG_MOSIX_UDB=y
# CONFIG_MOSIX_DEBUG is not set
# CONFIG_MOSIX_CHEAT_MIGSELF is not set
CONFIG_MOSIX_WEEEEEEEEE=y
CONFIG_MOSIX_DIAG=y
CONFIG_MOSIX_SECUREPORTS=y
CONFIG_MOSIX_DISCLOSURE=3
CONFIG_QKERNEL_EXT=y
CONFIG_MOSIX_DFSA=y
CONFIG_MOSIX_FS=y
CONFIG_MOSIX_PIPE_EXCEPTIONS=y
CONFIG_QOS_JID=y
...
</PROGRAMLISTING>

and compile it with:

<PROGRAMLISTING>
make dep bzImage modules modules_install
</PROGRAMLISTING>

After compilation install the new kernel with the openMosix options within 
you boot-loader e.g.
insert an entry for the new kernel in /etc/lilo.conf and run lilo after 
that.
</PARA><PARA>

Reboot and your openMosix-cluster(node)  is up!

</PARA>
</SECT2>
<SECT2><TITLE>hpc.map</TITLE>

<PARA>


Syntax of the /etc/hpc.map file

Before starting openMosix there has to be a /etc/hpc.map configuration 
file (on each node) 
which must be equal on each node. The hpc.map contains three space 
separated fields:
<PROGRAMLISTING>
openMosix-Node_ID               IP-Address(or hostname)          Range-size
</PROGRAMLISTING>

An example hpc.map could look like this:
<PROGRAMLISTING>
1       node1   1
2       node2   1
3       node3   1
4       node4   1
</PROGRAMLISTING>

or

<PROGRAMLISTING>
1       192.168.1.1     1
2       192.168.1.2     1
3       192.168.1.3     1
4       192.168.1.4     1
</PROGRAMLISTING>

or with the help of the range-size these both examples are equal with:

<PROGRAMLISTING>
1       192.168.1.1     4
</PROGRAMLISTING>

openMosix "counts-up" the last byte of the ip-address of the node according 
to its openMosix-ID.
(if you use a range-size greater than 1 you have to use ip-addresses 
instead of hostnames)
</PARA><PARA>
If a node has more than one network-interfaces it can be configured with 
the ALIAS option in the 
range-size field (which is equal to set the range-size to 0) e.g.

<PROGRAMLISTING>
1       192.168.1.1     1
2       192.168.1.2     1
3       192.168.1.3     1
4       192.168.1.4     1
4       192.168.10.10   ALIAS
</PROGRAMLISTING>
Here the node with the openMosix-ID 4 has two network-interfaces 
(192.168.1.4 + 192.168.10.10) which
are both visible to openMosix.
</PARA><PARA>

Always be sure to run the same openMosix version AND configuration on each 
of your Cluster nodes!
</PARA><PARA>

Start openMosix with the "setpe" utility on each node :

setpe -w -f /etc/hpc.map

Execute this command (which will be described later on in this HOWTO) on 
every node in your openMosix
cluster. Installation finished now, the cluster is up and running :)
</PARA>
</SECT2><SECT2><TITLE>MFS</TITLE>

<PARA>



At first the CONFIG_MOSIX_FS option in the kernel configuration has to be 
enabled. If the current kernel
 was compiled without this option recompilation with this option enabled 
is required. Also the UIDs and
GUIDs in the cluster must be equivalent.
The CONFIG_MOSIX_DFSA option in the kernel is optional but of course 
required if DFSA should be used.
To mount MFS on the cluster there has to be an additional fstab-entry on 
each nodes /etc/fstab.
</PARA><PARA>
for DFSA enabled:
<PROGRAMLISTING>
mfs_mnt         /mfs            mfs     dfsa=1          0 0
</PROGRAMLISTING>

for DFSA disabled:
<PROGRAMLISTING>
mfs_mnt          /mfs           mfs     dfsa=0          0 0
</PROGRAMLISTING>

the syntax of this fstab-entry is:
<PROGRAMLISTING>
[device_name]           [mount_point]   mfs     defaults        0 0
</PROGRAMLISTING>

After mounting the /mfs mount-point on each node, each nodes file-system is 
accessible through the 
/mfs/[openMosix_ID]/ directories. 
</PARA><PARA>

With the help of some symbolic links all cluster-nodes can access the same 
data e.g. /work on node1
<PROGRAMLISTING>
on node2 :      ln -s /mfs/1/work /work
on node3 :      ln -s /mfs/1/work /work
on node3 :      ln -s /mfs/1/work /work
...
</PROGRAMLISTING>
Now every node can read+write from and to /work !
</PARA><PARA>

The following special files are excluded from the MFS:

<SIMPLELIST><MEMBER>the /proc directory</>
<MEMBER>special files which are not regular-files, directories or symbolic 
links 
e.g. /dev/hda1
</>
</SIMPLELIST>
</PARA>
<PARA>
Creating links like:

<PROGRAMLISTING>
ln -s /mfs/1/mfs/1/usr         
</PROGRAMLISTING>
 
or              

<PROGRAMLISTING>
ln -s /mfs/1/mfs/3/usr
</PROGRAMLISTING>

is invalid.
</PARA>
<PARA>
The following system calls are supported without sending the migrated 
process (which executes this call
on its home (remote) node) going back to its home node:
</PARA>
<PARA>


read, readv, write, writev, readahead,  lseek, llseek, open, creat, close, 
dup, dup2, fcntl/fcntl64,
getdents, getdents64, old_readdir, fsync, fdatasync, chdir, fchdir, 
getcwd, stat, stat64, newstat,
lstat, lstat64, newlstat, fstat, fstat64, newfstat, access, truncate, 
truncate64, ftruncate, ftruncate64,
chmod, chown, chown16, lchown, lchown16, fchmod, fchown, fchown16, utime, 
utimes, symlink, readlink,
mkdir, rmdir, link, unlink, rename

</PARA>
<PARA>

Here are situations when system calls on DFSA mounted filesystems may not 
work:
<SIMPLELIST>
<MEMBER>different mfs/dfsa configuration on the cluster-nodes</>
<MEMBER>dup2 if the second file-pointer is non-DFSA</>
<MEMBER>chdir/fchdir if the parent dir is non-DFSA</>
<MEMBER>pathnames that leave the DFSA-filesystem</>
<MEMBER>when the process which executes the system-call is being traced</>
<MEMBER>if there are pending requests for the process which executes the 
system-call</>

</SIMPLELIST>

</PARA>



<PARA>
Next to the  /mfs/1/  /mfs/2/  and so on files you will find some other directories as well.
</para>
<table frame=all><title>Other Directories</title>
<tgroup cols=2 align=left>
<tbody>
<row><entry>
/mfs/here  </entry>  <entry> The current node where your process runs</entry>
</row>
<row><entry>/mfs/home</entry>  <entry>    Your home node</entry></row>
<row><entry>/mfs/magic    </entry><entry> The current node when used by the "creat" system call
                (or an "open" with the "O_CREAT" option) - otherwise,
                the last node on which an MFS magical file was
                successfully created (this is very useful for creating
                temporary-files, then immediately unlinking them)</entry></row>
<row><entry>/mfs/lastexec </entry><entry> The node on which the process last issued a successful
                "execve" system-call. </entry></row>
<row><entry>/mfs/selected </entry><entry>The node you selected by either your process itself or
                one of its ancesstors (before forking this process),
                writing a number into "/proc/self/selected".</entry></row>
</tbody></tgroup></table>
<para>

Note that these magic files are all 'per proccess'. That is their
contents is dependent upon which proccess opens them.
</PARA>


</SECT2>

</SECT1>

<SECT1><TITLE>Red Hat and openMosix</TITLE>
<PARA>
If you are running a RedHat 7.2 or 7.3 version,  this is probalby the easiest *Mosix install you have 
ever done.  
Choose the appropriate openMosix RPM's from sourceforge.  They have precompiled kernels (as I write this 
2.4.17) that work seamlessly , I have tested them on several machines including Latptops with PCMCIA 
cards and Servers with SCSI disks.  If you are a grub user the kernel rpm even modifies your grub.conf.
So all you have to do is install 2 rpm's

<programlisting>
rpm -vih openmosix-kernel-2.4.17-openmosix1.i686.rpm openmosix-tools-0.2.0-1.i386.rpm
</programlisting>

And edit your /etc/mosix.map

Since this seems to be a problem for lot's of people let's go with another example.
Say you have 3 machines. 192.168.10.220, 192.168.10.78 and 192.168.10.84.

Your mosix.map wil look like this.
<programlisting>
[root@oscar0 root]# more /etc/mosix.map 
# MOSIX CONFIGURATION
# ===================
#
# Each line should contain 3 fields, mapping IP addresses to MOSIX node-numbers:
# 1) first MOSIX node-number in range.
# 2) IP address of the above node (or node-name from /etc/hosts).
# 3) number of nodes in this range.
#
# Example: 10 machines with IP 192.168.1.50 - 192.168.1.59
# 1	   192.168.1.50	    10
#
# MOSIX-#  IP  number-of-nodes
# ============================
1 192.168.10.220 1
2 192.168.10.78  1
3 192.168.10.84  1
</programlisting>


Now by rebooting the different machines with the newly installed kernel you will get 1 step closer to 
having a working cluster.
</para>
<para>
Most RedHat installations have 1 extra thing to fix. You often get the following error.
<programlisting>
[root@inspon root]# /etc/init.d/openmosix start 
Initializing openMosix...
setpe: the supplied table is well-formatted,
but my IP address (127.0.0.1) is not there!
</programlisting>

This means that your hostname is not listed in /etc/hosts with the same ip as in your mosix.map 
You might have a machine called omosix1.localhost.org  in your hostfile listed as 
<programlisting>
127.0.0.1	omosix1.localhost.org localhost 
</programlisting>

If you modify your /etc/hosts to look like below.  openMosix will have less troubles starting up.

<programlisting>
192.168.10.78   omosix1.localhost.org
127.0.0.1       localhost 
</programlisting>

<programlisting>
[root@inspon root]# /etc/init.d/openmosix start 
Initializing openMosix...
[root@inspon root]# /etc/init.d/openmosix status
This is MOSIX node #2
Network protocol: 2 (AF_INET)
MOSIX range     1-1     begins at 192.168.10.220
MOSIX range     2-2     begins at inspon.localhost.be
MOSIX range     3-3     begins at 192.168.10.84
Total configured: 3
</programlisting>


 </PARA>
</SECT1>

<SECT1><TITLE>Suse 7.1 and Mosix (obsolete)</TITLE>
<SECT2><TITLE>Versions Required</TITLE>
<PARA>

The following is based on using SuSE 7.1 (German Version), Linux
  Kernel 2.2.19, and Mosix 0.98.0. 

</PARA><PARA>  

  The Linux Kernel 2.2.18 sources are part of the SuSE distribution. Do
  not use the default SuSE 2.2.18 kernel, as it is heavily patched with
  SuSE stuff. Get the patch for 2.2.19 from your favorite mirror such as
  . If there are further patches for the 2.2.* kernel
  RROR URL HERE by the time you read this text, get those, too. 

</PARA><PARA>

  If one of your machines is a laptop with a network connection via
  PCMCIA, you will need the PCMCIA sources, too. They are included in
  the SuSE distribution as MISSING: RPM HERE.

</PARA><PARA>

  Mosix 0.98.0 for the 2.2.19 kernel can be found on
  <ulink url="http://www.mosix.org"><citetitle>http://www.mosix.org/</citetitle></ulink> as MOSIX-0.98.0.tar.gz . While you are there, you
  might want to get some of the contributed software like qps or mtop.
  Again, if there is a version more current than 0.98.0 by the time you
  read this, get it instead.

</PARA><PARA>

  SuSE 7.1 ships with a Mosix-package as a rpm MISSING: RPM HERE
  Ignore this package. It is based on Kernel 2.2.18 and seems to have
  been modified by SuSE (see /usr/share/doc/packages/mosix/README.SUSE).
  You are better off installing the Mosix sources and installing from
  scratch.

</PARA>
</SECT2>

<SECT2><TITLE>Installation</TITLE>
<PARA> 

We're assuming your hardware and basic Linux system are all set up
correctly and that you can at least telnet (or ssh) between the different
machines. The procedure is described for one machine.  Log in as root.
Install the sources for the 2.2.18 Kernel in /usr/src. SuSE will place them
there automatically as /usr/src/linux-2.2.18 if you install the RPM RPM
NAME. Rename the directory to /usr/src/linux-2.2.19. Remove the existing
link /usr/src/linux and create a new one to this directory with

 
<PROGRAMLISTING>
        ln -s /usr/src/linux-2.2.19 linux
</PROGRAMLISTING>
     
(assuming you are in /usr/src).  Patch the kernel to 2.2.19 (or whatever
the current version is). If you do not know to do this, check the Linux
Kernel HOWTO.  Make a directory /usr/src/linux-2.2.19-mosix and copy the
contents of the vanilla kernel /usr/src/linux-2.2.19 there with the command
 
<PROGRAMLISTING>
        cp -rp linux-2.2.19/* linux-2.2.19-mosix/ 
</PROGRAMLISTING>
 
     
     
This gives you a clean backup kernel to fall back on if something goes
wrong. Remove the /usr/src/linux link (again). Create a link /usr/src/linux
to /usr/src/linux-2.2.19-mosix with

 
<PROGRAMLISTING>
        ln -s /usr/src/linux-2.2.19-mosix linux
</PROGRAMLISTING>

to make life easier.  Change to /tmp, copy the Mosix sources there and
unpack them with the command

 
<PROGRAMLISTING>
        tar xfz MOSIX-0.98.0.tar.gz
</PROGRAMLISTING>
 
Do not unpack the resulting tar archives such as /tmp/user.tar that appear.

</PARA>
</SECT2>
<SECT2>
<TITLE>Setup</TITLE>
<itemizedlist>
<listitem>
<para>

 Run the install script /tmp/mosix.install and follow instructions. 

</para><para>

     
Mosix should be enabled for run level 3 (full multiuser with network, no
xdm) and 5 (full multiuser with network and xdm). There is no run level 4
in SuSE 7.1.

</para><para>

The Mosix install script does not give you the option of creating a boot
floppy instead of an image. If you want a boot floppy, you will have to run
"make bzdisk" after the install script is through.

</para><para>

     Do not repeat /not/ reboot. 
</para>
</listitem>
<listitem>
<para>
   The install script in Mosix 0.98.0 is made for Red Hat distributions
     and therefore fails to set up some SuSE files correctly. It tries
     to put stuff in /sbin/init.d/, which in fact is /etc/init.d/ (or
     /etc/rc.d/) with SuSE. Also, there is no /etc/rc.d/init.d/ in SuSE.
     
     So: 
     <itemizedlist>
     <listitem>
     <para>

      Copy /tmp/mosix.init to /etc/init.d/mosix and make it executable 
        with the command 
 
        
<PROGRAMLISTING>
                chmod 754 /etc/init.d/mosix
</PROGRAMLISTING>
 
     </para>
     </listitem>

     <listitem><para>
 MISSING - MODIFY ATD stuff "/etc/rc.d/init.d/ATD" BY 
HAND
     </para></listitem>

     <listitem><para>
      MISSING - MODIFY THE "/etc/cron.daily/slocate.cron" FILE
     </para></listitem>
     <listitem><para>
     
     The other files - /etc/inittab, /etc/inetd.conf, /etc/lilo.conf -
     are modified correctly.
     </para></listitem>
     </itemizedlist>
</para></listitem>
<listitem><para>
   Edit the file /etc/inittab to prevent some processes from migrating
     to other nodes by inserting the command "/bin/mosrun -h" in the
     following lines:
</para>
<para>
     Run levels:
 
<PROGRAMLISTING>
        l0:0:wait:/bin/mosrun -h /etc/init.d/rc 0
        l1:1:wait:/bin/mosrun -h /etc/init.d/rc 1
        l2:2:wait:/bin/mosrun -h /etc/init.d/rc 2
        l3:3:wait:/bin/mosrun -h /etc/init.d/rc 3
        l5:5:wait:/bin/mosrun -h /etc/init.d/rc 5
        l6:6:wait:/bin/mosrun -h /etc/init.d/rc 6
</PROGRAMLISTING>

     (Remember, there is no run level 4 in SuSE 7.1)
</para>
<para>
     Shutdown and sulogin:
</para>
<PROGRAMLISTING>
    ~~:S:respawn:/bin/mosrun -h /sbin/sulogin
        ca::ctrlaltdel:/bin/mosrun -h /sbin/shutdown -r -t 4 now
        sh:12345:powerfail:/bin/mosrun -h /sbin/shutdown -h now THE \
           POWER IS FAILING
</PROGRAMLISTING>
<para> 

     It is not necessary to prevent the /sbin/mingetty processes from
     migrating - in fact, if you do, all of the child processes started
     from your login shell will be locked, too [Note to German readers:
     This is mistake in the article "Zwischen Multiprocessing und
     Cluster-Computing" on Mosix in "Linux-Magazin" 6/2000]. 
</para>
</listitem>
<listitem>
<para>
   To enable the processes started by your window manager to migrate,
     edit the files ~/.xinitrc and ~/.xsession by going to the end of the
     file and changing the line "exec $WINDOWMANAGER" to

  
<PROGRAMLISTING>
       exec /bin/mosrun -l $WINDOWMANAGER
</PROGRAMLISTING>
 

     You should be able to enable migration for all users' window
     mangers by modifying the equivalent line in /etc/X11/xdm/Xsession
     MISSING: NOT TESTED YET. However, see section 8 "Notes" for
     reasons why you might not want to do this by default.
</para>
</listitem>
<listitem>
<para>
  The command to start and stop Mosix (do not repeat /not/ do this 
     now) is

 
<PROGRAMLISTING>
       /etc/init.d/mosix {start|stop|status|restart|reload} 
</PROGRAMLISTING>
 

     To have Mosix start automatically at boot time, go to /etc/init.d/ . 
     In the subdirectories ./rc3.d and ./rc5.d, create the following
     links:

 
<PROGRAMLISTING>
        ln -s ../mosix S30mosix
        ln -s ../mosix K01mosix
</PROGRAMLISTING>
 

     The first line causes Mosix to be called as the last part of the
     install procedure for the given run level, the second line closes it
     down as one of the first services. 

</para>
</listitem>
<listitem>
<para>

  Create a file /etc/mosix.map following the instructions in the
     Mosix documentation. In the most simple case, you will have n
     computers which have their IP-addresses in sequence so that the map
     file will simply look like

 
<PROGRAMLISTING>
        1   IP-address of first node  n 
</PROGRAMLISTING>

This is where a lot of errors occur, let me clarify this with an example.
Suppose you have 5 machines,  10.0.0.1, 10.0.0.2 , 10.0.0.100 , 10.0.0.101 
and 10.0.0.150 your mosix.map would look like 

<PROGRAMLISTING>
	1  10.0.0.1	2
	3  10.0.0.100   2
        5  10.0.0.150   1
</PROGRAMLISTING>

PLEASE VERIFY THIS !!!!!!!
</para>
</listitem>
<listitem><para>
   Run "/etc/versionate", which will most probably tell you that the
     Mosix module already has a version. Do it anyway. 
</para></listitem>
<listitem><para>

  Now, finally, reboot. The computer should come up running Mosix. 

</PARA></listitem></itemizedlist>
</SECT2>

</SECT1>

<SECT1><TITLE>Debian and Mosix (to be replaced with openMosix 
version)</TITLE>
<PARA>
Installing mosix on a Debian based machine can be done as described below 

First step is downloading the packages from the net.  Since we are using a
Debian setup we needed

<ulink url="http://packages.debian.org/unstable/net/mosix.html"><citetitle>http://packages.debian.org/unstable/net/mosix.html
</citetitle></ulink>
<ulink url="http://packages.debian.org/unstable/net/kernel-patch-mosix.html"><citetitle>http://packages.debian.org/unstable/net/kernel-patch-mosix.html
</citetitle></ulink>
<ulink 
url="http://packages.debian.org/unstable/net/mps.html"><citetitle>http://packages.debian.org/unstable/net/mps.html
</citetitle></ulink>

You can also apt-get install them ;)

Next part is making the kernel mosix capable.

Copy the patch.$kernel version in to your /usr/src/linux-$version
directory run


<PROGRAMLISTING>
patch -p0 < patches.2.4.10
</PROGRAMLISTING>

Check your kernel config and run

<PROGRAMLISTING>
make dep ; make clean ; make bzImage ; make modules ; make modules_install
</PROGRAMLISTING>

You now will need to edit your /etc/mosix/mosix.map
This file has a bit a strange layout.
We have 2 machines 192.168.10.65 and 192.168.10.94

This gives us a mosix.map that looks like
<PROGRAMLISTING>
1 192.168.10.65 1
2 192.168.10.94 1
</PROGRAMLISTING>


After rebooting with this kernel (lilo etc you know the drill),
you then should have a cluster of mosix machines that talk to each-other and
that do migration of processes.


You can test that by running the following small script  ..
<PROGRAMLISTING>
awk 'BEGIN {for(i=0;i<10000;i++)for(j=0;j<10000;j++);}'
</PROGRAMLISTING>
a couple of times, and monitor it`s behaviour with mon
where you will see that it spreads the load between 2 different nodes.

If you have enabled Process-arrival messages in your kernel you will
notice that each time a remote (guest) process arrives on your node a
Weeeeeee will be printed and each time a local proces returns you will see
a Woooooo on your console.  So basically If you don`t see any of those
messages during the running of a program and if you have this option
enabled in your kernel you might conclude that no processes migrate.



We also setup Mosixview (0.8) on the debian machine
<PROGRAMLISTING>
apt-get install mosixview
</PROGRAMLISTING>

In order to be able to actually use Mosixview you will need to run it from
a user who can log in to the different nodes as root.   We suggest you set
this up using ssh.  Please note that there is a difference between the ssh
and ssh2 implemtations .. if you have a identity.pub ssh wil check  
authorized_keys, if you have id_rsa.pub you will need authorized_keys2 !!


Mosixview gives you a nice interface that shows the load of different
machines and gives you the possibility to migrate processes manually.

A detailed  discussion of Mosixview can be found elsewhere in this 
document.
</PARA>
</SECT1>

<SECT1><TITLE>Other distributions</TITLE>
<PARA>
Based on the explanations above you should be able to install Mosix on 
most other Linux platforms. 
</PARA>
</SECT1>


</CHAPTER>

